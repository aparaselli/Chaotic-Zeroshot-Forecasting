{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chronos-forecasting in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: accelerate<1,>=0.32 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from chronos-forecasting) (0.34.2)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from chronos-forecasting) (2.5.1)\n",
      "Requirement already satisfied: transformers<4.48,>=4.30 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from chronos-forecasting) (4.47.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/athulithparaselli/.local/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from accelerate<1,>=0.32->chronos-forecasting) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/athulithparaselli/.local/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/athulithparaselli/.local/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (72.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from torch<3,>=2.0->chronos-forecasting) (1.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from transformers<4.48,>=4.30->chronos-forecasting) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from transformers<4.48,>=4.30->chronos-forecasting) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from transformers<4.48,>=4.30->chronos-forecasting) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from transformers<4.48,>=4.30->chronos-forecasting) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch<3,>=2.0->chronos-forecasting) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/athulithparaselli/.local/lib/python3.12/site-packages (from jinja2->torch<3,>=2.0->chronos-forecasting) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from requests->transformers<4.48,>=4.30->chronos-forecasting) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from requests->transformers<4.48,>=4.30->chronos-forecasting) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from requests->transformers<4.48,>=4.30->chronos-forecasting) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/ChronosHAB/lib/python3.12/site-packages (from requests->transformers<4.48,>=4.30->chronos-forecasting) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install chronos-forecasting\n",
    "import pandas as pd  # requires: pip install pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "from chronos import ChronosBoltPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from chronos.chronos import ChronosPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WQL FUNCTION (Sourced from chatGPT)\n",
    "\n",
    "\n",
    "def quantile_loss(y_true, y_pred, alpha):\n",
    "    \"\"\"\n",
    "    Computes quantile loss for a given quantile level alpha.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: True values (numpy array of shape (N,))\n",
    "    - y_pred: Predicted quantile values (numpy array of shape (N,))\n",
    "    - alpha: Quantile level (scalar)\n",
    "\n",
    "    Returns:\n",
    "    - Quantile loss (scalar)\n",
    "    \"\"\"\n",
    "    diff = y_true - y_pred\n",
    "    return np.maximum(alpha * diff, (alpha - 1) * diff).mean()\n",
    "\n",
    "def weighted_quantile_loss(y_true, y_pred_quantiles, quantile_levels):\n",
    "    \"\"\"\n",
    "    Computes the Weighted Quantile Loss (WQL) with the modified shape of predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: True values (numpy array of shape (N,))\n",
    "    - y_pred_quantiles: Predicted quantiles (numpy array of shape (K, N), where K is the number of quantiles)\n",
    "    - quantile_levels: List or array of quantile levels (K,)\n",
    "\n",
    "    Returns:\n",
    "    - Weighted Quantile Loss (scalar)\n",
    "    \"\"\"\n",
    "    assert y_pred_quantiles.shape[0] == len(quantile_levels), \"Mismatch in quantile dimensions\"\n",
    "\n",
    "    # Compute WQL for each quantile\n",
    "    wql_per_quantile = [\n",
    "        (2 * quantile_loss(y_true, y_pred_quantiles[j, :], alpha)) / np.abs(y_true).sum()\n",
    "        for j, alpha in enumerate(quantile_levels)\n",
    "    ]\n",
    "    \n",
    "    # Final WQL (mean over quantiles)\n",
    "    return np.mean(wql_per_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASE\n",
    "def mase(y_true, y_pred, y_past, S):\n",
    "    \"\"\"\n",
    "    Computes the Mean Absolute Scaled Error (MASE) while ignoring NaNs in the input arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Actual values (numpy array of shape (H,))\n",
    "    - y_pred: Predicted values (numpy array of shape (H,))\n",
    "    - y_past: Historical values (numpy array of shape (C,)) for computing seasonal naive MAE\n",
    "    - S: Seasonality parameter (integer)\n",
    "\n",
    "    Returns:\n",
    "    - MASE score (scalar)\n",
    "    \"\"\"\n",
    "    # Mask NaNs in y_true and corresponding elements in y_pred\n",
    "    valid_mask = ~np.isnan(y_true)\n",
    "    y_true_filtered = y_true[valid_mask]\n",
    "    y_pred_filtered = y_pred[valid_mask]\n",
    "\n",
    "    # Mask NaNs in y_past for seasonal naive MAE calculation\n",
    "    past_valid_mask = ~np.isnan(y_past)\n",
    "    y_past_filtered = y_past[past_valid_mask]\n",
    "\n",
    "    # Ensure enough data remains after filtering\n",
    "    if len(y_true_filtered) == 0 or len(y_past_filtered) <= S:\n",
    "        return np.inf  # Avoid division by zero or invalid computation\n",
    "\n",
    "    H = len(y_true_filtered)  # Adjusted prediction horizon\n",
    "    C = len(y_past_filtered)  # Adjusted context length\n",
    "\n",
    "    # Compute the numerator (MAE of forecast)\n",
    "    numerator = np.sum(np.abs(y_pred_filtered - y_true_filtered)) / H\n",
    "\n",
    "    # Compute the denominator (MAE of seasonal naive forecast)\n",
    "    denominator = np.sum(np.abs(y_past_filtered[:-S] - y_past_filtered[S:])) / (C - S)\n",
    "\n",
    "    return numerator / denominator if denominator != 0 else np.inf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/74w_zv855875xvjtmhp4g1xw0000gn/T/ipykernel_38103/959312731.py:35: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  (2 * quantile_loss(y_true, y_pred_quantiles[j, :], alpha)) / np.abs(y_true).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RIU_MASE</th>\n",
       "      <th>RIU_WQL</th>\n",
       "      <th>Lake_Zurich_MASE</th>\n",
       "      <th>Lake_Zurich_WQL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>1.138655</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>0.718103</td>\n",
       "      <td>0.09024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RIU_MASE   RIU_WQL  Lake_Zurich_MASE  Lake_Zurich_WQL\n",
       "Baseline  1.138655  0.061646          0.718103          0.09024"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics(y_true,y_pred,quantiles,y_past, s):\n",
    "    wql = weighted_quantile_loss(y_true,y_pred,quantiles)\n",
    "    mase_met = mase(y_true,y_pred[4],y_past,s)\n",
    "    return wql, mase_met\n",
    "#1. Ecological Datasets\n",
    "#2. Samples of attractors that were use in training \n",
    "#3. Sample of attractors that were not in training \n",
    "#4. (For Experiment 4 and 5 only) Samples of ecological data that \n",
    "def forecast_pipeline(pipeline, model_name):\n",
    "    quantiles = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "    RIU = pd.read_csv('Data/RIU_cleaned.csv')\n",
    "    forecast = pipeline.predict_quantiles(\n",
    "        context=torch.tensor(RIU[\"Total abundance\"].iloc[:-12]), prediction_length=12\n",
    "    )\n",
    "    forecast = forecast[0].permute(0, 2, 1) \n",
    "    # IMPORTANT METRIC BELOW (Ecological Data)\n",
    "    RIU_wql, RIU_mase = metrics(RIU[\"Total abundance\"].iloc[-12:].to_numpy(), forecast[0].numpy(), quantiles,RIU[\"Total abundance\"].iloc[:-12].to_numpy(), 12)\n",
    "    LZ = pd.read_csv('Data/LZ_data.csv').iloc[1:-31].reset_index()\n",
    "    LZ_wql_agg = []\n",
    "    LZ_mase_agg = []\n",
    "    test_LZ_wql_agg = []\n",
    "    test_LZ_mase_agg = []\n",
    "    test_LZs = ['Cyclops sp SU C1-C3',\n",
    "    'Gymnodinium sp',\n",
    "    'Erkenia subaequiciliata',\n",
    "    'Aphanizomenon flos-aquae',\n",
    "    'Asterionella formosa',\n",
    "    'Elakatothrix gelatinosa',\n",
    "    'Staurastrum sp',\n",
    "    'Diaptomus sp C4-C5']\n",
    "    for column in LZ.columns[2:]:\n",
    "        forecast = pipeline.predict_quantiles(\n",
    "        context=torch.tensor(LZ[column].iloc[:-12]), prediction_length=12)\n",
    "        forecast = forecast[0].permute(0, 2, 1) \n",
    "        LZ_wql, LZ_mase = metrics(LZ[column].iloc[-12:].to_numpy(), forecast[0].numpy(), quantiles,LZ[column].iloc[:-12].to_numpy(), 12)\n",
    "        if LZ_wql == np.inf:\n",
    "            LZ_wql = 1\n",
    "        LZ_wql_agg.append(LZ_wql)\n",
    "        LZ_mase_agg.append(LZ_mase)\n",
    "        if column in test_LZs:\n",
    "            test_LZ_wql_agg.append(LZ_wql)\n",
    "            test_LZ_mase_agg.append(LZ_mase)\n",
    "    #IMPORTANT METRIC BELOW (Ecological data)\n",
    "    mean_LZ_wql = np.mean(LZ_wql_agg)\n",
    "    mean_LZ_mase = np.mean(LZ_mase_agg)\n",
    "    test_mean_LZ_wql = np.mean(test_LZ_wql_agg)\n",
    "    test_mean_LZ_mase = np.mean(test_LZ_mase_agg)\n",
    "    \n",
    "    #Synthetic attractors \n",
    "    synth_att = pd.read_csv('Data/Synthetic_attractor_test_data.csv')\n",
    "    synt_wql_agg = []\n",
    "    synt_mase_agg = []\n",
    "    for column in synth_att.columns[1:]:\n",
    "        forecast = pipeline.predict_quantiles(\n",
    "        context=torch.tensor(synth_att[column].iloc[:-57]), prediction_length=57)\n",
    "        forecast = forecast[0].permute(0, 2, 1) \n",
    "        synt_wql, synt_mase = metrics(synth_att[column].iloc[-57:].to_numpy(), forecast[0].numpy(), quantiles,synth_att[column].iloc[:-57].to_numpy(), 57)\n",
    "        if synt_wql == np.inf:\n",
    "            LZ_wql = 1\n",
    "        synt_mase_agg.append(synt_mase)\n",
    "        synt_wql_agg.append(synt_wql)\n",
    "    #IMPORTNANT METRIC BELOW (synthetic data)\n",
    "    mean_synt_wql = np.mean(synt_wql_agg)\n",
    "    mean_synt_mase = np.mean(synt_mase_agg)\n",
    "\n",
    "    unseen_synth_att = pd.read_csv('Data/hyper_hr.csv')\n",
    "\n",
    "    #Create dataframes:\n",
    "    ecological_one = {'RIU_MASE': [RIU_mase],'RIU_WQL': [RIU_wql],'Lake_Zurich_MASE':[mean_LZ_mase], 'Lake_Zurich_WQL':[mean_LZ_wql]}\n",
    "    ecological_one = pd.DataFrame(ecological_one)\n",
    "    ecological_one.index = [model_name]\n",
    "    ecological_two = {'RIU_MASE': [RIU_mase],'RIU_WQL': [RIU_wql],'Test_Lake_Zurich_MASE':[test_mean_LZ_mase], 'Lake_Zurich_WQL':[test_mean_LZ_wql]}\n",
    "    ecological_two = pd.DataFrame(ecological_two)\n",
    "    ecological_two.index = [model_name]\n",
    "    synthetic_one = {'Synthetic_MASE': [mean_synt_mase],'Synthetic_WQL': [mean_synt_wql]}\n",
    "    synthetic_one = pd.DataFrame(synthetic_one)\n",
    "    synthetic_one.index = [model_name]\n",
    "\n",
    "    return ecological_one, synthetic_one,'dud',ecological_two\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ec1, syn1, syn2, ec2 = forecast_pipeline(pipeline,'Baseline')\n",
    "ec1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselinepipeline = ChronosBoltPipeline.from_pretrained(\n",
    "    \"amazon/chronos-bolt-tiny\",\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "finetunepipeline = ChronosPipeline.from_pretrained(\n",
    "\"scripts/training/output/run-6/checkpoint-final/\")\n",
    "random_weight_pipeline = ChronosPipeline.from_pretrained(\n",
    "\"scripts/training/output/run-8/checkpoint-final/\")\n",
    "mixed_tiny_pipeline = ChronosPipeline.from_pretrained(\n",
    "\"scripts/training/output/mixed-data-mini/checkpoint-final/\")\n",
    "mixed_large_pipeline = ChronosPipeline.from_pretrained(\n",
    "\"scripts/training/output/mixed-data/checkpoint-200000/\")\n",
    "pipeline_list = [baselinepipeline,finetunepipeline,random_weight_pipeline,mixed_tiny_pipeline]\n",
    "pipeline_names = ['baseline', 'Finetuned','Random Weight Initialization', 'Mixed tiny', 'Mixed large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/74w_zv855875xvjtmhp4g1xw0000gn/T/ipykernel_38103/959312731.py:35: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  (2 * quantile_loss(y_true, y_pred_quantiles[j, :], alpha)) / np.abs(y_true).sum()\n",
      "/var/folders/5y/74w_zv855875xvjtmhp4g1xw0000gn/T/ipykernel_38103/959312731.py:35: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  (2 * quantile_loss(y_true, y_pred_quantiles[j, :], alpha)) / np.abs(y_true).sum()\n"
     ]
    }
   ],
   "source": [
    "ec1, syn1, syn2, ec2 = forecast_pipeline(pipeline_list[0],pipeline_names[0])\n",
    "ec1\n",
    "for i in range(1,len(pipeline_list)):\n",
    "    curr_ec1, curr_syn1, curr_syn2, curr_ec2 = forecast_pipeline(pipeline_list[i],pipeline_names[i])\n",
    "    ec1 = pd.concat([ec1, curr_ec1], ignore_index=True)\n",
    "    syn1 = pd.concat([syn1, curr_syn1], ignore_index=True)\n",
    "    #syn2 = pd.concat([syn2, curr_syn2], ignore_index=True)\n",
    "    ec2 = pd.concat([ec2, curr_ec2], ignore_index=True)\n",
    "    print(f'Iteration {i} done')\n",
    "ec1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chronosHAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
