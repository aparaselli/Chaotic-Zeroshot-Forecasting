{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.85,
  "eval_steps": 500,
  "global_step": 170000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0025,
      "grad_norm": 0.2755284607410431,
      "learning_rate": 2.5e-05,
      "loss": 8.0049,
      "step": 500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.22223015129566193,
      "learning_rate": 5e-05,
      "loss": 7.0121,
      "step": 1000
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.19085565209388733,
      "learning_rate": 7.5e-05,
      "loss": 6.5489,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2770683169364929,
      "learning_rate": 0.0001,
      "loss": 6.2333,
      "step": 2000
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.4478013515472412,
      "learning_rate": 0.000125,
      "loss": 5.7504,
      "step": 2500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.8724038600921631,
      "learning_rate": 0.00015,
      "loss": 5.1321,
      "step": 3000
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.7944466471672058,
      "learning_rate": 0.000175,
      "loss": 4.672,
      "step": 3500
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0942325592041016,
      "learning_rate": 0.0002,
      "loss": 4.3598,
      "step": 4000
    },
    {
      "epoch": 0.0225,
      "grad_norm": 1.028058648109436,
      "learning_rate": 0.00022500000000000002,
      "loss": 4.1417,
      "step": 4500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.9266738295555115,
      "learning_rate": 0.00025,
      "loss": 3.9744,
      "step": 5000
    },
    {
      "epoch": 0.0275,
      "grad_norm": 1.1964426040649414,
      "learning_rate": 0.000275,
      "loss": 3.8552,
      "step": 5500
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5211143493652344,
      "learning_rate": 0.0003,
      "loss": 3.7415,
      "step": 6000
    },
    {
      "epoch": 0.0325,
      "grad_norm": 1.1099122762680054,
      "learning_rate": 0.00032500000000000004,
      "loss": 3.6639,
      "step": 6500
    },
    {
      "epoch": 0.035,
      "grad_norm": 1.1981841325759888,
      "learning_rate": 0.00035,
      "loss": 3.5894,
      "step": 7000
    },
    {
      "epoch": 0.0375,
      "grad_norm": 1.1666449308395386,
      "learning_rate": 0.000375,
      "loss": 3.5035,
      "step": 7500
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.120750069618225,
      "learning_rate": 0.0004,
      "loss": 3.4065,
      "step": 8000
    },
    {
      "epoch": 0.0425,
      "grad_norm": 1.0387226343154907,
      "learning_rate": 0.000425,
      "loss": 3.3594,
      "step": 8500
    },
    {
      "epoch": 0.045,
      "grad_norm": 1.1613445281982422,
      "learning_rate": 0.00045000000000000004,
      "loss": 3.2944,
      "step": 9000
    },
    {
      "epoch": 0.0475,
      "grad_norm": 1.0987235307693481,
      "learning_rate": 0.000475,
      "loss": 3.2394,
      "step": 9500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9910199642181396,
      "learning_rate": 0.0005,
      "loss": 3.2081,
      "step": 10000
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.9770273566246033,
      "learning_rate": 0.0005250000000000001,
      "loss": 3.1623,
      "step": 10500
    },
    {
      "epoch": 0.055,
      "grad_norm": 1.0777878761291504,
      "learning_rate": 0.00055,
      "loss": 3.1097,
      "step": 11000
    },
    {
      "epoch": 0.0575,
      "grad_norm": 1.1786452531814575,
      "learning_rate": 0.000575,
      "loss": 3.0821,
      "step": 11500
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1373220682144165,
      "learning_rate": 0.0006,
      "loss": 3.0453,
      "step": 12000
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.9960458278656006,
      "learning_rate": 0.000625,
      "loss": 3.0117,
      "step": 12500
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.1738498210906982,
      "learning_rate": 0.0006500000000000001,
      "loss": 2.9964,
      "step": 13000
    },
    {
      "epoch": 0.0675,
      "grad_norm": 1.0692952871322632,
      "learning_rate": 0.000675,
      "loss": 2.9765,
      "step": 13500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9470510482788086,
      "learning_rate": 0.0007,
      "loss": 2.9467,
      "step": 14000
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.9020401239395142,
      "learning_rate": 0.000725,
      "loss": 2.9242,
      "step": 14500
    },
    {
      "epoch": 0.075,
      "grad_norm": 1.0254045724868774,
      "learning_rate": 0.00075,
      "loss": 2.8907,
      "step": 15000
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.9512869715690613,
      "learning_rate": 0.0007750000000000001,
      "loss": 2.8767,
      "step": 15500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9258245825767517,
      "learning_rate": 0.0008,
      "loss": 2.8537,
      "step": 16000
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.0389676094055176,
      "learning_rate": 0.000825,
      "loss": 2.8648,
      "step": 16500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.875550389289856,
      "learning_rate": 0.00085,
      "loss": 2.8361,
      "step": 17000
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.8412075042724609,
      "learning_rate": 0.000875,
      "loss": 2.8237,
      "step": 17500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8710130453109741,
      "learning_rate": 0.0009000000000000001,
      "loss": 2.8069,
      "step": 18000
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.8694050312042236,
      "learning_rate": 0.000925,
      "loss": 2.8054,
      "step": 18500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.9275988936424255,
      "learning_rate": 0.00095,
      "loss": 2.7817,
      "step": 19000
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.7413091659545898,
      "learning_rate": 0.000975,
      "loss": 2.7713,
      "step": 19500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8398870229721069,
      "learning_rate": 0.001,
      "loss": 2.768,
      "step": 20000
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.7992689609527588,
      "learning_rate": 0.0009972222222222223,
      "loss": 2.7436,
      "step": 20500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.9139820337295532,
      "learning_rate": 0.0009944444444444445,
      "loss": 2.7331,
      "step": 21000
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.9432749152183533,
      "learning_rate": 0.0009916666666666667,
      "loss": 2.7186,
      "step": 21500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8553193211555481,
      "learning_rate": 0.000988888888888889,
      "loss": 2.7235,
      "step": 22000
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.8307945728302002,
      "learning_rate": 0.0009861111111111112,
      "loss": 2.6881,
      "step": 22500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.9663397073745728,
      "learning_rate": 0.0009833333333333332,
      "loss": 2.6684,
      "step": 23000
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.7934462428092957,
      "learning_rate": 0.0009805555555555555,
      "loss": 2.6744,
      "step": 23500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8736383318901062,
      "learning_rate": 0.0009777777777777777,
      "loss": 2.667,
      "step": 24000
    },
    {
      "epoch": 0.1225,
      "grad_norm": 1.0335010290145874,
      "learning_rate": 0.000975,
      "loss": 2.6404,
      "step": 24500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.7993679642677307,
      "learning_rate": 0.0009722222222222222,
      "loss": 2.6291,
      "step": 25000
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.9113073945045471,
      "learning_rate": 0.0009694444444444444,
      "loss": 2.6132,
      "step": 25500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9447520971298218,
      "learning_rate": 0.0009666666666666667,
      "loss": 2.6221,
      "step": 26000
    },
    {
      "epoch": 0.1325,
      "grad_norm": 1.0915998220443726,
      "learning_rate": 0.0009638888888888889,
      "loss": 2.6146,
      "step": 26500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.8569995164871216,
      "learning_rate": 0.0009611111111111112,
      "loss": 2.6005,
      "step": 27000
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.767702579498291,
      "learning_rate": 0.0009583333333333334,
      "loss": 2.5956,
      "step": 27500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9408414959907532,
      "learning_rate": 0.0009555555555555556,
      "loss": 2.5908,
      "step": 28000
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.0825061798095703,
      "learning_rate": 0.0009527777777777778,
      "loss": 2.5696,
      "step": 28500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.9873946309089661,
      "learning_rate": 0.00095,
      "loss": 2.5761,
      "step": 29000
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.9563546776771545,
      "learning_rate": 0.0009472222222222222,
      "loss": 2.5427,
      "step": 29500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9177813529968262,
      "learning_rate": 0.0009444444444444445,
      "loss": 2.5522,
      "step": 30000
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.8867344260215759,
      "learning_rate": 0.0009416666666666667,
      "loss": 2.5424,
      "step": 30500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.9767298698425293,
      "learning_rate": 0.000938888888888889,
      "loss": 2.54,
      "step": 31000
    },
    {
      "epoch": 0.1575,
      "grad_norm": 1.3121973276138306,
      "learning_rate": 0.0009361111111111111,
      "loss": 2.5309,
      "step": 31500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1446796655654907,
      "learning_rate": 0.0009333333333333333,
      "loss": 2.5289,
      "step": 32000
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.9174524545669556,
      "learning_rate": 0.0009305555555555556,
      "loss": 2.5057,
      "step": 32500
    },
    {
      "epoch": 0.165,
      "grad_norm": 1.3080657720565796,
      "learning_rate": 0.0009277777777777778,
      "loss": 2.5049,
      "step": 33000
    },
    {
      "epoch": 0.1675,
      "grad_norm": 1.0645796060562134,
      "learning_rate": 0.000925,
      "loss": 2.5073,
      "step": 33500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9190815687179565,
      "learning_rate": 0.0009222222222222223,
      "loss": 2.5072,
      "step": 34000
    },
    {
      "epoch": 0.1725,
      "grad_norm": 1.0085959434509277,
      "learning_rate": 0.0009194444444444444,
      "loss": 2.4939,
      "step": 34500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.8902914524078369,
      "learning_rate": 0.0009166666666666666,
      "loss": 2.4741,
      "step": 35000
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.0916814804077148,
      "learning_rate": 0.0009138888888888889,
      "loss": 2.4884,
      "step": 35500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9855893850326538,
      "learning_rate": 0.0009111111111111111,
      "loss": 2.4817,
      "step": 36000
    },
    {
      "epoch": 0.1825,
      "grad_norm": 1.0061044692993164,
      "learning_rate": 0.0009083333333333334,
      "loss": 2.4671,
      "step": 36500
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.1686521768569946,
      "learning_rate": 0.0009055555555555556,
      "loss": 2.467,
      "step": 37000
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.9476125836372375,
      "learning_rate": 0.0009027777777777778,
      "loss": 2.4683,
      "step": 37500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.127593994140625,
      "learning_rate": 0.0009000000000000001,
      "loss": 2.4631,
      "step": 38000
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.267197608947754,
      "learning_rate": 0.0008972222222222223,
      "loss": 2.4465,
      "step": 38500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.9196543097496033,
      "learning_rate": 0.0008944444444444445,
      "loss": 2.4544,
      "step": 39000
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.3010649681091309,
      "learning_rate": 0.0008916666666666667,
      "loss": 2.443,
      "step": 39500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.076006531715393,
      "learning_rate": 0.0008888888888888888,
      "loss": 2.4486,
      "step": 40000
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.966355562210083,
      "learning_rate": 0.0008861111111111111,
      "loss": 2.4373,
      "step": 40500
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.2470664978027344,
      "learning_rate": 0.0008833333333333333,
      "loss": 2.4167,
      "step": 41000
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.4840776920318604,
      "learning_rate": 0.0008805555555555555,
      "loss": 2.4166,
      "step": 41500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8393589854240417,
      "learning_rate": 0.0008777777777777778,
      "loss": 2.4112,
      "step": 42000
    },
    {
      "epoch": 0.2125,
      "grad_norm": 1.332276701927185,
      "learning_rate": 0.000875,
      "loss": 2.4204,
      "step": 42500
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.0049221515655518,
      "learning_rate": 0.0008722222222222223,
      "loss": 2.4071,
      "step": 43000
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.0221027135849,
      "learning_rate": 0.0008694444444444445,
      "loss": 2.4193,
      "step": 43500
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.075404405593872,
      "learning_rate": 0.0008666666666666667,
      "loss": 2.4015,
      "step": 44000
    },
    {
      "epoch": 0.2225,
      "grad_norm": 1.1441863775253296,
      "learning_rate": 0.000863888888888889,
      "loss": 2.4119,
      "step": 44500
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.0580530166625977,
      "learning_rate": 0.0008611111111111112,
      "loss": 2.4086,
      "step": 45000
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.9026246666908264,
      "learning_rate": 0.0008583333333333333,
      "loss": 2.3844,
      "step": 45500
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0413882732391357,
      "learning_rate": 0.0008555555555555556,
      "loss": 2.3849,
      "step": 46000
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.9945863485336304,
      "learning_rate": 0.0008527777777777777,
      "loss": 2.3917,
      "step": 46500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.0613161325454712,
      "learning_rate": 0.00085,
      "loss": 2.3969,
      "step": 47000
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.9945915341377258,
      "learning_rate": 0.0008472222222222222,
      "loss": 2.3835,
      "step": 47500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.98283451795578,
      "learning_rate": 0.0008444444444444444,
      "loss": 2.3698,
      "step": 48000
    },
    {
      "epoch": 0.2425,
      "grad_norm": 1.3250346183776855,
      "learning_rate": 0.0008416666666666667,
      "loss": 2.3801,
      "step": 48500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.024021863937378,
      "learning_rate": 0.0008388888888888889,
      "loss": 2.3693,
      "step": 49000
    },
    {
      "epoch": 0.2475,
      "grad_norm": 1.0984121561050415,
      "learning_rate": 0.0008361111111111111,
      "loss": 2.3575,
      "step": 49500
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.188629150390625,
      "learning_rate": 0.0008333333333333334,
      "loss": 2.3521,
      "step": 50000
    },
    {
      "epoch": 0.2525,
      "grad_norm": 1.1682363748550415,
      "learning_rate": 0.0008305555555555556,
      "loss": 2.3766,
      "step": 50500
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.2172335386276245,
      "learning_rate": 0.0008277777777777778,
      "loss": 2.3601,
      "step": 51000
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.18943190574646,
      "learning_rate": 0.000825,
      "loss": 2.3644,
      "step": 51500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0161300897598267,
      "learning_rate": 0.0008222222222222222,
      "loss": 2.3504,
      "step": 52000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 1.2034080028533936,
      "learning_rate": 0.0008194444444444445,
      "loss": 2.3659,
      "step": 52500
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.1535791158676147,
      "learning_rate": 0.0008166666666666667,
      "loss": 2.3462,
      "step": 53000
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.2223997116088867,
      "learning_rate": 0.000813888888888889,
      "loss": 2.3319,
      "step": 53500
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.17854905128479,
      "learning_rate": 0.0008111111111111111,
      "loss": 2.3491,
      "step": 54000
    },
    {
      "epoch": 0.2725,
      "grad_norm": 1.0952318906784058,
      "learning_rate": 0.0008083333333333333,
      "loss": 2.3374,
      "step": 54500
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.003746747970581,
      "learning_rate": 0.0008055555555555556,
      "loss": 2.3354,
      "step": 55000
    },
    {
      "epoch": 0.2775,
      "grad_norm": 1.2293168306350708,
      "learning_rate": 0.0008027777777777778,
      "loss": 2.3369,
      "step": 55500
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0423318147659302,
      "learning_rate": 0.0008,
      "loss": 2.3405,
      "step": 56000
    },
    {
      "epoch": 0.2825,
      "grad_norm": 1.0424410104751587,
      "learning_rate": 0.0007972222222222223,
      "loss": 2.3189,
      "step": 56500
    },
    {
      "epoch": 0.285,
      "grad_norm": 1.039792776107788,
      "learning_rate": 0.0007944444444444444,
      "loss": 2.3084,
      "step": 57000
    },
    {
      "epoch": 0.2875,
      "grad_norm": 1.1277624368667603,
      "learning_rate": 0.0007916666666666666,
      "loss": 2.3185,
      "step": 57500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.026243805885315,
      "learning_rate": 0.0007888888888888889,
      "loss": 2.3227,
      "step": 58000
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.348097801208496,
      "learning_rate": 0.0007861111111111111,
      "loss": 2.3237,
      "step": 58500
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.0055654048919678,
      "learning_rate": 0.0007833333333333334,
      "loss": 2.3185,
      "step": 59000
    },
    {
      "epoch": 0.2975,
      "grad_norm": 1.190608024597168,
      "learning_rate": 0.0007805555555555556,
      "loss": 2.3039,
      "step": 59500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1199089288711548,
      "learning_rate": 0.0007777777777777778,
      "loss": 2.3191,
      "step": 60000
    },
    {
      "epoch": 0.3025,
      "grad_norm": 1.0641883611679077,
      "learning_rate": 0.0007750000000000001,
      "loss": 2.3034,
      "step": 60500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.0580445528030396,
      "learning_rate": 0.0007722222222222223,
      "loss": 2.3132,
      "step": 61000
    },
    {
      "epoch": 0.3075,
      "grad_norm": 1.2421987056732178,
      "learning_rate": 0.0007694444444444445,
      "loss": 2.2922,
      "step": 61500
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0960018634796143,
      "learning_rate": 0.0007666666666666667,
      "loss": 2.2999,
      "step": 62000
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.0726573467254639,
      "learning_rate": 0.0007638888888888888,
      "loss": 2.3014,
      "step": 62500
    },
    {
      "epoch": 0.315,
      "grad_norm": 1.1120861768722534,
      "learning_rate": 0.0007611111111111111,
      "loss": 2.2953,
      "step": 63000
    },
    {
      "epoch": 0.3175,
      "grad_norm": 1.1545003652572632,
      "learning_rate": 0.0007583333333333333,
      "loss": 2.2964,
      "step": 63500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.285988211631775,
      "learning_rate": 0.0007555555555555555,
      "loss": 2.2859,
      "step": 64000
    },
    {
      "epoch": 0.3225,
      "grad_norm": 1.2148423194885254,
      "learning_rate": 0.0007527777777777778,
      "loss": 2.2941,
      "step": 64500
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.1464585065841675,
      "learning_rate": 0.00075,
      "loss": 2.2853,
      "step": 65000
    },
    {
      "epoch": 0.3275,
      "grad_norm": 1.1285672187805176,
      "learning_rate": 0.0007472222222222223,
      "loss": 2.2856,
      "step": 65500
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2780861854553223,
      "learning_rate": 0.0007444444444444445,
      "loss": 2.2773,
      "step": 66000
    },
    {
      "epoch": 0.3325,
      "grad_norm": 1.0675575733184814,
      "learning_rate": 0.0007416666666666667,
      "loss": 2.2732,
      "step": 66500
    },
    {
      "epoch": 0.335,
      "grad_norm": 1.1803038120269775,
      "learning_rate": 0.000738888888888889,
      "loss": 2.2782,
      "step": 67000
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.0876401662826538,
      "learning_rate": 0.0007361111111111112,
      "loss": 2.2773,
      "step": 67500
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.182017207145691,
      "learning_rate": 0.0007333333333333333,
      "loss": 2.277,
      "step": 68000
    },
    {
      "epoch": 0.3425,
      "grad_norm": 1.1215907335281372,
      "learning_rate": 0.0007305555555555556,
      "loss": 2.2679,
      "step": 68500
    },
    {
      "epoch": 0.345,
      "grad_norm": 1.158577799797058,
      "learning_rate": 0.0007277777777777777,
      "loss": 2.2625,
      "step": 69000
    },
    {
      "epoch": 0.3475,
      "grad_norm": 1.097868800163269,
      "learning_rate": 0.000725,
      "loss": 2.2814,
      "step": 69500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0587122440338135,
      "learning_rate": 0.0007222222222222222,
      "loss": 2.2664,
      "step": 70000
    },
    {
      "epoch": 0.3525,
      "grad_norm": 1.1563867330551147,
      "learning_rate": 0.0007194444444444444,
      "loss": 2.2652,
      "step": 70500
    },
    {
      "epoch": 0.355,
      "grad_norm": 1.261726975440979,
      "learning_rate": 0.0007166666666666667,
      "loss": 2.2482,
      "step": 71000
    },
    {
      "epoch": 0.3575,
      "grad_norm": 1.2203123569488525,
      "learning_rate": 0.0007138888888888889,
      "loss": 2.2551,
      "step": 71500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0535458326339722,
      "learning_rate": 0.0007111111111111111,
      "loss": 2.2653,
      "step": 72000
    },
    {
      "epoch": 0.3625,
      "grad_norm": 1.1386938095092773,
      "learning_rate": 0.0007083333333333334,
      "loss": 2.25,
      "step": 72500
    },
    {
      "epoch": 0.365,
      "grad_norm": 1.2012499570846558,
      "learning_rate": 0.0007055555555555556,
      "loss": 2.2602,
      "step": 73000
    },
    {
      "epoch": 0.3675,
      "grad_norm": 1.1823512315750122,
      "learning_rate": 0.0007027777777777778,
      "loss": 2.2563,
      "step": 73500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1437987089157104,
      "learning_rate": 0.0007,
      "loss": 2.2305,
      "step": 74000
    },
    {
      "epoch": 0.3725,
      "grad_norm": 1.074427843093872,
      "learning_rate": 0.0006972222222222222,
      "loss": 2.2567,
      "step": 74500
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.1696480512619019,
      "learning_rate": 0.0006944444444444445,
      "loss": 2.244,
      "step": 75000
    },
    {
      "epoch": 0.3775,
      "grad_norm": 1.32588791847229,
      "learning_rate": 0.0006916666666666667,
      "loss": 2.2512,
      "step": 75500
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2311595678329468,
      "learning_rate": 0.000688888888888889,
      "loss": 2.2415,
      "step": 76000
    },
    {
      "epoch": 0.3825,
      "grad_norm": 1.2975441217422485,
      "learning_rate": 0.0006861111111111111,
      "loss": 2.2345,
      "step": 76500
    },
    {
      "epoch": 0.385,
      "grad_norm": 1.2234690189361572,
      "learning_rate": 0.0006833333333333333,
      "loss": 2.2406,
      "step": 77000
    },
    {
      "epoch": 0.3875,
      "grad_norm": 1.2853002548217773,
      "learning_rate": 0.0006805555555555556,
      "loss": 2.2481,
      "step": 77500
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.236536979675293,
      "learning_rate": 0.0006777777777777778,
      "loss": 2.2512,
      "step": 78000
    },
    {
      "epoch": 0.3925,
      "grad_norm": 1.1216905117034912,
      "learning_rate": 0.000675,
      "loss": 2.2378,
      "step": 78500
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.371161699295044,
      "learning_rate": 0.0006722222222222223,
      "loss": 2.2503,
      "step": 79000
    },
    {
      "epoch": 0.3975,
      "grad_norm": 1.2209408283233643,
      "learning_rate": 0.0006694444444444444,
      "loss": 2.2452,
      "step": 79500
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2731189727783203,
      "learning_rate": 0.0006666666666666666,
      "loss": 2.2371,
      "step": 80000
    },
    {
      "epoch": 0.4025,
      "grad_norm": 1.3297500610351562,
      "learning_rate": 0.0006638888888888889,
      "loss": 2.2323,
      "step": 80500
    },
    {
      "epoch": 0.405,
      "grad_norm": 1.2396045923233032,
      "learning_rate": 0.0006611111111111111,
      "loss": 2.2127,
      "step": 81000
    },
    {
      "epoch": 0.4075,
      "grad_norm": 1.3170483112335205,
      "learning_rate": 0.0006583333333333334,
      "loss": 2.2136,
      "step": 81500
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0940907001495361,
      "learning_rate": 0.0006555555555555556,
      "loss": 2.2267,
      "step": 82000
    },
    {
      "epoch": 0.4125,
      "grad_norm": 1.1673704385757446,
      "learning_rate": 0.0006527777777777778,
      "loss": 2.229,
      "step": 82500
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.2146726846694946,
      "learning_rate": 0.0006500000000000001,
      "loss": 2.2233,
      "step": 83000
    },
    {
      "epoch": 0.4175,
      "grad_norm": 1.3033915758132935,
      "learning_rate": 0.0006472222222222223,
      "loss": 2.209,
      "step": 83500
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3451694250106812,
      "learning_rate": 0.0006444444444444444,
      "loss": 2.208,
      "step": 84000
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.2665108442306519,
      "learning_rate": 0.0006416666666666667,
      "loss": 2.2202,
      "step": 84500
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.2604715824127197,
      "learning_rate": 0.0006388888888888888,
      "loss": 2.2265,
      "step": 85000
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.2255772352218628,
      "learning_rate": 0.0006361111111111111,
      "loss": 2.2039,
      "step": 85500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2070046663284302,
      "learning_rate": 0.0006333333333333333,
      "loss": 2.2125,
      "step": 86000
    },
    {
      "epoch": 0.4325,
      "grad_norm": 1.412043571472168,
      "learning_rate": 0.0006305555555555555,
      "loss": 2.2205,
      "step": 86500
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.3423820734024048,
      "learning_rate": 0.0006277777777777778,
      "loss": 2.2133,
      "step": 87000
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.1514582633972168,
      "learning_rate": 0.000625,
      "loss": 2.2088,
      "step": 87500
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4204411506652832,
      "learning_rate": 0.0006222222222222223,
      "loss": 2.2009,
      "step": 88000
    },
    {
      "epoch": 0.4425,
      "grad_norm": 1.237144947052002,
      "learning_rate": 0.0006194444444444445,
      "loss": 2.2088,
      "step": 88500
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.257920265197754,
      "learning_rate": 0.0006166666666666667,
      "loss": 2.201,
      "step": 89000
    },
    {
      "epoch": 0.4475,
      "grad_norm": 1.4140043258666992,
      "learning_rate": 0.000613888888888889,
      "loss": 2.1987,
      "step": 89500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3317261934280396,
      "learning_rate": 0.0006111111111111112,
      "loss": 2.2028,
      "step": 90000
    },
    {
      "epoch": 0.4525,
      "grad_norm": 1.3222215175628662,
      "learning_rate": 0.0006083333333333333,
      "loss": 2.2011,
      "step": 90500
    },
    {
      "epoch": 0.455,
      "grad_norm": 1.2127662897109985,
      "learning_rate": 0.0006055555555555556,
      "loss": 2.194,
      "step": 91000
    },
    {
      "epoch": 0.4575,
      "grad_norm": 1.3680349588394165,
      "learning_rate": 0.0006027777777777777,
      "loss": 2.1995,
      "step": 91500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3159154653549194,
      "learning_rate": 0.0006,
      "loss": 2.1958,
      "step": 92000
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.3198890686035156,
      "learning_rate": 0.0005972222222222222,
      "loss": 2.1867,
      "step": 92500
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.2715026140213013,
      "learning_rate": 0.0005944444444444444,
      "loss": 2.2068,
      "step": 93000
    },
    {
      "epoch": 0.4675,
      "grad_norm": 1.2229429483413696,
      "learning_rate": 0.0005916666666666667,
      "loss": 2.1888,
      "step": 93500
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2426764965057373,
      "learning_rate": 0.0005888888888888889,
      "loss": 2.1824,
      "step": 94000
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.1411502361297607,
      "learning_rate": 0.0005861111111111111,
      "loss": 2.186,
      "step": 94500
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.299712061882019,
      "learning_rate": 0.0005833333333333334,
      "loss": 2.18,
      "step": 95000
    },
    {
      "epoch": 0.4775,
      "grad_norm": 1.3246538639068604,
      "learning_rate": 0.0005805555555555556,
      "loss": 2.1753,
      "step": 95500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3364372253417969,
      "learning_rate": 0.0005777777777777778,
      "loss": 2.1807,
      "step": 96000
    },
    {
      "epoch": 0.4825,
      "grad_norm": 1.2698168754577637,
      "learning_rate": 0.000575,
      "loss": 2.1836,
      "step": 96500
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.2967778444290161,
      "learning_rate": 0.0005722222222222222,
      "loss": 2.1857,
      "step": 97000
    },
    {
      "epoch": 0.4875,
      "grad_norm": 1.3451019525527954,
      "learning_rate": 0.0005694444444444445,
      "loss": 2.1886,
      "step": 97500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4009697437286377,
      "learning_rate": 0.0005666666666666667,
      "loss": 2.1796,
      "step": 98000
    },
    {
      "epoch": 0.4925,
      "grad_norm": 1.2427562475204468,
      "learning_rate": 0.000563888888888889,
      "loss": 2.1787,
      "step": 98500
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.2346606254577637,
      "learning_rate": 0.0005611111111111111,
      "loss": 2.1865,
      "step": 99000
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.2681866884231567,
      "learning_rate": 0.0005583333333333333,
      "loss": 2.1759,
      "step": 99500
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.451784372329712,
      "learning_rate": 0.0005555555555555556,
      "loss": 2.1714,
      "step": 100000
    },
    {
      "epoch": 0.5025,
      "grad_norm": 1.3269997835159302,
      "learning_rate": 0.0005527777777777778,
      "loss": 2.1668,
      "step": 100500
    },
    {
      "epoch": 0.505,
      "grad_norm": 1.2534021139144897,
      "learning_rate": 0.00055,
      "loss": 2.1761,
      "step": 101000
    },
    {
      "epoch": 0.5075,
      "grad_norm": 1.3293884992599487,
      "learning_rate": 0.0005472222222222223,
      "loss": 2.1639,
      "step": 101500
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1471571922302246,
      "learning_rate": 0.0005444444444444444,
      "loss": 2.1743,
      "step": 102000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 1.283318042755127,
      "learning_rate": 0.0005416666666666666,
      "loss": 2.1529,
      "step": 102500
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.352429986000061,
      "learning_rate": 0.0005388888888888889,
      "loss": 2.164,
      "step": 103000
    },
    {
      "epoch": 0.5175,
      "grad_norm": 1.4596686363220215,
      "learning_rate": 0.0005361111111111111,
      "loss": 2.1673,
      "step": 103500
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2756344079971313,
      "learning_rate": 0.0005333333333333334,
      "loss": 2.167,
      "step": 104000
    },
    {
      "epoch": 0.5225,
      "grad_norm": 1.2742680311203003,
      "learning_rate": 0.0005305555555555556,
      "loss": 2.1556,
      "step": 104500
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.172121286392212,
      "learning_rate": 0.0005277777777777778,
      "loss": 2.1543,
      "step": 105000
    },
    {
      "epoch": 0.5275,
      "grad_norm": 1.3365120887756348,
      "learning_rate": 0.0005250000000000001,
      "loss": 2.1681,
      "step": 105500
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.372435212135315,
      "learning_rate": 0.0005222222222222223,
      "loss": 2.1638,
      "step": 106000
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.325992226600647,
      "learning_rate": 0.0005194444444444444,
      "loss": 2.1587,
      "step": 106500
    },
    {
      "epoch": 0.535,
      "grad_norm": 1.325222134590149,
      "learning_rate": 0.0005166666666666667,
      "loss": 2.153,
      "step": 107000
    },
    {
      "epoch": 0.5375,
      "grad_norm": 1.2317339181900024,
      "learning_rate": 0.0005138888888888888,
      "loss": 2.1445,
      "step": 107500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2493563890457153,
      "learning_rate": 0.0005111111111111111,
      "loss": 2.1527,
      "step": 108000
    },
    {
      "epoch": 0.5425,
      "grad_norm": 1.4071338176727295,
      "learning_rate": 0.0005083333333333333,
      "loss": 2.1523,
      "step": 108500
    },
    {
      "epoch": 0.545,
      "grad_norm": 1.4197463989257812,
      "learning_rate": 0.0005055555555555555,
      "loss": 2.1489,
      "step": 109000
    },
    {
      "epoch": 0.5475,
      "grad_norm": 1.4456993341445923,
      "learning_rate": 0.0005027777777777778,
      "loss": 2.1457,
      "step": 109500
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4592760801315308,
      "learning_rate": 0.0005,
      "loss": 2.1486,
      "step": 110000
    },
    {
      "epoch": 0.5525,
      "grad_norm": 1.3720461130142212,
      "learning_rate": 0.0004972222222222222,
      "loss": 2.1435,
      "step": 110500
    },
    {
      "epoch": 0.555,
      "grad_norm": 1.231472373008728,
      "learning_rate": 0.0004944444444444445,
      "loss": 2.146,
      "step": 111000
    },
    {
      "epoch": 0.5575,
      "grad_norm": 1.4594709873199463,
      "learning_rate": 0.0004916666666666666,
      "loss": 2.1368,
      "step": 111500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4423837661743164,
      "learning_rate": 0.0004888888888888889,
      "loss": 2.1367,
      "step": 112000
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.2102024555206299,
      "learning_rate": 0.0004861111111111111,
      "loss": 2.1367,
      "step": 112500
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.3220512866973877,
      "learning_rate": 0.00048333333333333334,
      "loss": 2.1453,
      "step": 113000
    },
    {
      "epoch": 0.5675,
      "grad_norm": 1.1947702169418335,
      "learning_rate": 0.0004805555555555556,
      "loss": 2.1442,
      "step": 113500
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2597334384918213,
      "learning_rate": 0.0004777777777777778,
      "loss": 2.1247,
      "step": 114000
    },
    {
      "epoch": 0.5725,
      "grad_norm": 1.4010056257247925,
      "learning_rate": 0.000475,
      "loss": 2.1253,
      "step": 114500
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.3261533975601196,
      "learning_rate": 0.00047222222222222224,
      "loss": 2.1296,
      "step": 115000
    },
    {
      "epoch": 0.5775,
      "grad_norm": 1.3919954299926758,
      "learning_rate": 0.0004694444444444445,
      "loss": 2.1135,
      "step": 115500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5138599872589111,
      "learning_rate": 0.00046666666666666666,
      "loss": 2.1325,
      "step": 116000
    },
    {
      "epoch": 0.5825,
      "grad_norm": 1.243333339691162,
      "learning_rate": 0.0004638888888888889,
      "loss": 2.1366,
      "step": 116500
    },
    {
      "epoch": 0.585,
      "grad_norm": 1.5168769359588623,
      "learning_rate": 0.00046111111111111114,
      "loss": 2.1432,
      "step": 117000
    },
    {
      "epoch": 0.5875,
      "grad_norm": 1.7378846406936646,
      "learning_rate": 0.0004583333333333333,
      "loss": 2.1292,
      "step": 117500
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4088270664215088,
      "learning_rate": 0.00045555555555555556,
      "loss": 2.1226,
      "step": 118000
    },
    {
      "epoch": 0.5925,
      "grad_norm": 1.3735463619232178,
      "learning_rate": 0.0004527777777777778,
      "loss": 2.125,
      "step": 118500
    },
    {
      "epoch": 0.595,
      "grad_norm": 1.2965054512023926,
      "learning_rate": 0.00045000000000000004,
      "loss": 2.1298,
      "step": 119000
    },
    {
      "epoch": 0.5975,
      "grad_norm": 1.3092987537384033,
      "learning_rate": 0.0004472222222222222,
      "loss": 2.135,
      "step": 119500
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.306200623512268,
      "learning_rate": 0.0004444444444444444,
      "loss": 2.1261,
      "step": 120000
    },
    {
      "epoch": 0.6025,
      "grad_norm": 1.5673104524612427,
      "learning_rate": 0.00044166666666666665,
      "loss": 2.1157,
      "step": 120500
    },
    {
      "epoch": 0.605,
      "grad_norm": 1.3704203367233276,
      "learning_rate": 0.0004388888888888889,
      "loss": 2.1264,
      "step": 121000
    },
    {
      "epoch": 0.6075,
      "grad_norm": 1.391148328781128,
      "learning_rate": 0.00043611111111111113,
      "loss": 2.1134,
      "step": 121500
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4698036909103394,
      "learning_rate": 0.00043333333333333337,
      "loss": 2.1243,
      "step": 122000
    },
    {
      "epoch": 0.6125,
      "grad_norm": 1.6701362133026123,
      "learning_rate": 0.0004305555555555556,
      "loss": 2.1128,
      "step": 122500
    },
    {
      "epoch": 0.615,
      "grad_norm": 1.1904652118682861,
      "learning_rate": 0.0004277777777777778,
      "loss": 2.1282,
      "step": 123000
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.3675446510314941,
      "learning_rate": 0.000425,
      "loss": 2.1206,
      "step": 123500
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3315187692642212,
      "learning_rate": 0.0004222222222222222,
      "loss": 2.1191,
      "step": 124000
    },
    {
      "epoch": 0.6225,
      "grad_norm": 1.2794052362442017,
      "learning_rate": 0.00041944444444444445,
      "loss": 2.1317,
      "step": 124500
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.240853190422058,
      "learning_rate": 0.0004166666666666667,
      "loss": 2.113,
      "step": 125000
    },
    {
      "epoch": 0.6275,
      "grad_norm": 1.3211534023284912,
      "learning_rate": 0.0004138888888888889,
      "loss": 2.1199,
      "step": 125500
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2273279428482056,
      "learning_rate": 0.0004111111111111111,
      "loss": 2.1031,
      "step": 126000
    },
    {
      "epoch": 0.6325,
      "grad_norm": 1.4722152948379517,
      "learning_rate": 0.00040833333333333336,
      "loss": 2.1103,
      "step": 126500
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.549613356590271,
      "learning_rate": 0.00040555555555555554,
      "loss": 2.1125,
      "step": 127000
    },
    {
      "epoch": 0.6375,
      "grad_norm": 1.3410305976867676,
      "learning_rate": 0.0004027777777777778,
      "loss": 2.1066,
      "step": 127500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3325889110565186,
      "learning_rate": 0.0004,
      "loss": 2.1056,
      "step": 128000
    },
    {
      "epoch": 0.6425,
      "grad_norm": 1.4457398653030396,
      "learning_rate": 0.0003972222222222222,
      "loss": 2.0988,
      "step": 128500
    },
    {
      "epoch": 0.645,
      "grad_norm": 1.4102391004562378,
      "learning_rate": 0.00039444444444444444,
      "loss": 2.1238,
      "step": 129000
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.4810740947723389,
      "learning_rate": 0.0003916666666666667,
      "loss": 2.1056,
      "step": 129500
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2320616245269775,
      "learning_rate": 0.0003888888888888889,
      "loss": 2.0952,
      "step": 130000
    },
    {
      "epoch": 0.6525,
      "grad_norm": 1.3946871757507324,
      "learning_rate": 0.00038611111111111116,
      "loss": 2.102,
      "step": 130500
    },
    {
      "epoch": 0.655,
      "grad_norm": 1.3846806287765503,
      "learning_rate": 0.00038333333333333334,
      "loss": 2.1146,
      "step": 131000
    },
    {
      "epoch": 0.6575,
      "grad_norm": 1.3777146339416504,
      "learning_rate": 0.00038055555555555553,
      "loss": 2.0993,
      "step": 131500
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2389206886291504,
      "learning_rate": 0.00037777777777777777,
      "loss": 2.0993,
      "step": 132000
    },
    {
      "epoch": 0.6625,
      "grad_norm": 1.399490475654602,
      "learning_rate": 0.000375,
      "loss": 2.0945,
      "step": 132500
    },
    {
      "epoch": 0.665,
      "grad_norm": 1.4558602571487427,
      "learning_rate": 0.00037222222222222225,
      "loss": 2.0908,
      "step": 133000
    },
    {
      "epoch": 0.6675,
      "grad_norm": 1.4343281984329224,
      "learning_rate": 0.0003694444444444445,
      "loss": 2.0932,
      "step": 133500
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4452506303787231,
      "learning_rate": 0.00036666666666666667,
      "loss": 2.1027,
      "step": 134000
    },
    {
      "epoch": 0.6725,
      "grad_norm": 1.668127417564392,
      "learning_rate": 0.00036388888888888886,
      "loss": 2.0871,
      "step": 134500
    },
    {
      "epoch": 0.675,
      "grad_norm": 2.0695934295654297,
      "learning_rate": 0.0003611111111111111,
      "loss": 2.0969,
      "step": 135000
    },
    {
      "epoch": 0.6775,
      "grad_norm": 1.3473892211914062,
      "learning_rate": 0.00035833333333333333,
      "loss": 2.0986,
      "step": 135500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4615353345870972,
      "learning_rate": 0.00035555555555555557,
      "loss": 2.0926,
      "step": 136000
    },
    {
      "epoch": 0.6825,
      "grad_norm": 1.3005907535552979,
      "learning_rate": 0.0003527777777777778,
      "loss": 2.0853,
      "step": 136500
    },
    {
      "epoch": 0.685,
      "grad_norm": 1.6911981105804443,
      "learning_rate": 0.00035,
      "loss": 2.0913,
      "step": 137000
    },
    {
      "epoch": 0.6875,
      "grad_norm": 1.8422656059265137,
      "learning_rate": 0.00034722222222222224,
      "loss": 2.1034,
      "step": 137500
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.60276460647583,
      "learning_rate": 0.0003444444444444445,
      "loss": 2.0874,
      "step": 138000
    },
    {
      "epoch": 0.6925,
      "grad_norm": 1.3102593421936035,
      "learning_rate": 0.00034166666666666666,
      "loss": 2.0864,
      "step": 138500
    },
    {
      "epoch": 0.695,
      "grad_norm": 1.507480263710022,
      "learning_rate": 0.0003388888888888889,
      "loss": 2.0835,
      "step": 139000
    },
    {
      "epoch": 0.6975,
      "grad_norm": 1.2616671323776245,
      "learning_rate": 0.00033611111111111114,
      "loss": 2.0854,
      "step": 139500
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.584641695022583,
      "learning_rate": 0.0003333333333333333,
      "loss": 2.0962,
      "step": 140000
    },
    {
      "epoch": 0.7025,
      "grad_norm": 1.4857854843139648,
      "learning_rate": 0.00033055555555555556,
      "loss": 2.0883,
      "step": 140500
    },
    {
      "epoch": 0.705,
      "grad_norm": 1.3459186553955078,
      "learning_rate": 0.0003277777777777778,
      "loss": 2.076,
      "step": 141000
    },
    {
      "epoch": 0.7075,
      "grad_norm": 1.55038321018219,
      "learning_rate": 0.00032500000000000004,
      "loss": 2.0727,
      "step": 141500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5101250410079956,
      "learning_rate": 0.0003222222222222222,
      "loss": 2.0824,
      "step": 142000
    },
    {
      "epoch": 0.7125,
      "grad_norm": 1.2814849615097046,
      "learning_rate": 0.0003194444444444444,
      "loss": 2.0759,
      "step": 142500
    },
    {
      "epoch": 0.715,
      "grad_norm": 1.8533326387405396,
      "learning_rate": 0.00031666666666666665,
      "loss": 2.0802,
      "step": 143000
    },
    {
      "epoch": 0.7175,
      "grad_norm": 1.3666305541992188,
      "learning_rate": 0.0003138888888888889,
      "loss": 2.0732,
      "step": 143500
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.571122407913208,
      "learning_rate": 0.0003111111111111111,
      "loss": 2.0838,
      "step": 144000
    },
    {
      "epoch": 0.7225,
      "grad_norm": 1.3990978002548218,
      "learning_rate": 0.00030833333333333337,
      "loss": 2.0734,
      "step": 144500
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.3380080461502075,
      "learning_rate": 0.0003055555555555556,
      "loss": 2.0712,
      "step": 145000
    },
    {
      "epoch": 0.7275,
      "grad_norm": 1.3621575832366943,
      "learning_rate": 0.0003027777777777778,
      "loss": 2.0651,
      "step": 145500
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.668703317642212,
      "learning_rate": 0.0003,
      "loss": 2.0894,
      "step": 146000
    },
    {
      "epoch": 0.7325,
      "grad_norm": 1.3959294557571411,
      "learning_rate": 0.0002972222222222222,
      "loss": 2.0737,
      "step": 146500
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.3253514766693115,
      "learning_rate": 0.00029444444444444445,
      "loss": 2.0687,
      "step": 147000
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.4525717496871948,
      "learning_rate": 0.0002916666666666667,
      "loss": 2.0888,
      "step": 147500
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4775786399841309,
      "learning_rate": 0.0002888888888888889,
      "loss": 2.0672,
      "step": 148000
    },
    {
      "epoch": 0.7425,
      "grad_norm": 1.5495563745498657,
      "learning_rate": 0.0002861111111111111,
      "loss": 2.0664,
      "step": 148500
    },
    {
      "epoch": 0.745,
      "grad_norm": 1.3258733749389648,
      "learning_rate": 0.00028333333333333335,
      "loss": 2.0674,
      "step": 149000
    },
    {
      "epoch": 0.7475,
      "grad_norm": 1.6415821313858032,
      "learning_rate": 0.00028055555555555554,
      "loss": 2.069,
      "step": 149500
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4294004440307617,
      "learning_rate": 0.0002777777777777778,
      "loss": 2.065,
      "step": 150000
    },
    {
      "epoch": 0.7525,
      "grad_norm": 1.5957781076431274,
      "learning_rate": 0.000275,
      "loss": 2.0786,
      "step": 150500
    },
    {
      "epoch": 0.755,
      "grad_norm": 1.5467208623886108,
      "learning_rate": 0.0002722222222222222,
      "loss": 2.0644,
      "step": 151000
    },
    {
      "epoch": 0.7575,
      "grad_norm": 1.4384565353393555,
      "learning_rate": 0.00026944444444444444,
      "loss": 2.0693,
      "step": 151500
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.512103796005249,
      "learning_rate": 0.0002666666666666667,
      "loss": 2.0713,
      "step": 152000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 1.356145977973938,
      "learning_rate": 0.0002638888888888889,
      "loss": 2.0539,
      "step": 152500
    },
    {
      "epoch": 0.765,
      "grad_norm": 1.370279312133789,
      "learning_rate": 0.00026111111111111116,
      "loss": 2.0544,
      "step": 153000
    },
    {
      "epoch": 0.7675,
      "grad_norm": 1.4830524921417236,
      "learning_rate": 0.00025833333333333334,
      "loss": 2.0645,
      "step": 153500
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.333998680114746,
      "learning_rate": 0.00025555555555555553,
      "loss": 2.064,
      "step": 154000
    },
    {
      "epoch": 0.7725,
      "grad_norm": 1.4986673593521118,
      "learning_rate": 0.00025277777777777777,
      "loss": 2.0618,
      "step": 154500
    },
    {
      "epoch": 0.775,
      "grad_norm": 1.4568804502487183,
      "learning_rate": 0.00025,
      "loss": 2.0396,
      "step": 155000
    },
    {
      "epoch": 0.7775,
      "grad_norm": 1.4284101724624634,
      "learning_rate": 0.00024722222222222224,
      "loss": 2.0535,
      "step": 155500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4247316122055054,
      "learning_rate": 0.00024444444444444443,
      "loss": 2.0599,
      "step": 156000
    },
    {
      "epoch": 0.7825,
      "grad_norm": 1.2720658779144287,
      "learning_rate": 0.00024166666666666667,
      "loss": 2.0417,
      "step": 156500
    },
    {
      "epoch": 0.785,
      "grad_norm": 1.3109242916107178,
      "learning_rate": 0.0002388888888888889,
      "loss": 2.0577,
      "step": 157000
    },
    {
      "epoch": 0.7875,
      "grad_norm": 1.324402093887329,
      "learning_rate": 0.00023611111111111112,
      "loss": 2.0672,
      "step": 157500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3900387287139893,
      "learning_rate": 0.00023333333333333333,
      "loss": 2.0433,
      "step": 158000
    },
    {
      "epoch": 0.7925,
      "grad_norm": 1.4425058364868164,
      "learning_rate": 0.00023055555555555557,
      "loss": 2.0508,
      "step": 158500
    },
    {
      "epoch": 0.795,
      "grad_norm": 1.6392182111740112,
      "learning_rate": 0.00022777777777777778,
      "loss": 2.0456,
      "step": 159000
    },
    {
      "epoch": 0.7975,
      "grad_norm": 1.5695894956588745,
      "learning_rate": 0.00022500000000000002,
      "loss": 2.0591,
      "step": 159500
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5019887685775757,
      "learning_rate": 0.0002222222222222222,
      "loss": 2.0508,
      "step": 160000
    },
    {
      "epoch": 0.8025,
      "grad_norm": 1.4998884201049805,
      "learning_rate": 0.00021944444444444444,
      "loss": 2.0473,
      "step": 160500
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.863893747329712,
      "learning_rate": 0.00021666666666666668,
      "loss": 2.0541,
      "step": 161000
    },
    {
      "epoch": 0.8075,
      "grad_norm": 1.4109972715377808,
      "learning_rate": 0.0002138888888888889,
      "loss": 2.0214,
      "step": 161500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5575295686721802,
      "learning_rate": 0.0002111111111111111,
      "loss": 2.0423,
      "step": 162000
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.4024591445922852,
      "learning_rate": 0.00020833333333333335,
      "loss": 2.0319,
      "step": 162500
    },
    {
      "epoch": 0.815,
      "grad_norm": 1.8238232135772705,
      "learning_rate": 0.00020555555555555556,
      "loss": 2.0356,
      "step": 163000
    },
    {
      "epoch": 0.8175,
      "grad_norm": 1.3883404731750488,
      "learning_rate": 0.00020277777777777777,
      "loss": 2.04,
      "step": 163500
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3997472524642944,
      "learning_rate": 0.0002,
      "loss": 2.0304,
      "step": 164000
    },
    {
      "epoch": 0.8225,
      "grad_norm": 1.3723636865615845,
      "learning_rate": 0.00019722222222222222,
      "loss": 2.0422,
      "step": 164500
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.4186166524887085,
      "learning_rate": 0.00019444444444444446,
      "loss": 2.0503,
      "step": 165000
    },
    {
      "epoch": 0.8275,
      "grad_norm": 1.6717429161071777,
      "learning_rate": 0.00019166666666666667,
      "loss": 2.0355,
      "step": 165500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3046844005584717,
      "learning_rate": 0.00018888888888888888,
      "loss": 2.0309,
      "step": 166000
    },
    {
      "epoch": 0.8325,
      "grad_norm": 1.5426687002182007,
      "learning_rate": 0.00018611111111111112,
      "loss": 2.0422,
      "step": 166500
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.4400737285614014,
      "learning_rate": 0.00018333333333333334,
      "loss": 2.0392,
      "step": 167000
    },
    {
      "epoch": 0.8375,
      "grad_norm": 1.7471901178359985,
      "learning_rate": 0.00018055555555555555,
      "loss": 2.0332,
      "step": 167500
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4483739137649536,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.0367,
      "step": 168000
    },
    {
      "epoch": 0.8425,
      "grad_norm": 1.4313815832138062,
      "learning_rate": 0.000175,
      "loss": 2.0386,
      "step": 168500
    },
    {
      "epoch": 0.845,
      "grad_norm": 1.3871757984161377,
      "learning_rate": 0.00017222222222222224,
      "loss": 2.0323,
      "step": 169000
    },
    {
      "epoch": 0.8475,
      "grad_norm": 1.455284595489502,
      "learning_rate": 0.00016944444444444445,
      "loss": 2.0336,
      "step": 169500
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4055836200714111,
      "learning_rate": 0.00016666666666666666,
      "loss": 2.0275,
      "step": 170000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2299814862848e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
