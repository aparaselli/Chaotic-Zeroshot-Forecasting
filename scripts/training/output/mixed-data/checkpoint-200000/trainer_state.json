{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0025,
      "grad_norm": 0.08402087539434433,
      "learning_rate": 0.0009975000000000001,
      "loss": 6.9986,
      "step": 500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.26369866728782654,
      "learning_rate": 0.000995,
      "loss": 5.5481,
      "step": 1000
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.8487398624420166,
      "learning_rate": 0.0009925000000000001,
      "loss": 4.5743,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6615681052207947,
      "learning_rate": 0.00099,
      "loss": 4.1597,
      "step": 2000
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.5265651345252991,
      "learning_rate": 0.0009875,
      "loss": 3.9506,
      "step": 2500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.5881938934326172,
      "learning_rate": 0.000985,
      "loss": 3.8226,
      "step": 3000
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.8194928169250488,
      "learning_rate": 0.0009825,
      "loss": 3.7283,
      "step": 3500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5795331597328186,
      "learning_rate": 0.00098,
      "loss": 3.6395,
      "step": 4000
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.7589713335037231,
      "learning_rate": 0.0009775,
      "loss": 3.6079,
      "step": 4500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.6024166941642761,
      "learning_rate": 0.000975,
      "loss": 3.5479,
      "step": 5000
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.7001314163208008,
      "learning_rate": 0.0009725000000000001,
      "loss": 3.5016,
      "step": 5500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6583829522132874,
      "learning_rate": 0.0009699999999999999,
      "loss": 3.4731,
      "step": 6000
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.8031817078590393,
      "learning_rate": 0.0009675,
      "loss": 3.4246,
      "step": 6500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.7260903120040894,
      "learning_rate": 0.000965,
      "loss": 3.3851,
      "step": 7000
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.8267017602920532,
      "learning_rate": 0.0009625,
      "loss": 3.3622,
      "step": 7500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9397307634353638,
      "learning_rate": 0.00096,
      "loss": 3.2973,
      "step": 8000
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.7799391746520996,
      "learning_rate": 0.0009575,
      "loss": 3.2836,
      "step": 8500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.9025956988334656,
      "learning_rate": 0.000955,
      "loss": 3.2532,
      "step": 9000
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.9816077947616577,
      "learning_rate": 0.0009525,
      "loss": 3.2409,
      "step": 9500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7569892406463623,
      "learning_rate": 0.00095,
      "loss": 3.2169,
      "step": 10000
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.8461318612098694,
      "learning_rate": 0.0009475,
      "loss": 3.2113,
      "step": 10500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.8632301092147827,
      "learning_rate": 0.000945,
      "loss": 3.1771,
      "step": 11000
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.7465617060661316,
      "learning_rate": 0.0009425,
      "loss": 3.1796,
      "step": 11500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8777176141738892,
      "learning_rate": 0.00094,
      "loss": 3.1464,
      "step": 12000
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.9392157793045044,
      "learning_rate": 0.0009375,
      "loss": 3.1378,
      "step": 12500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.7695891857147217,
      "learning_rate": 0.0009350000000000001,
      "loss": 3.1014,
      "step": 13000
    },
    {
      "epoch": 0.0675,
      "grad_norm": 1.209681510925293,
      "learning_rate": 0.0009325000000000001,
      "loss": 3.1027,
      "step": 13500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9222751259803772,
      "learning_rate": 0.00093,
      "loss": 3.1018,
      "step": 14000
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.873502790927887,
      "learning_rate": 0.0009275,
      "loss": 3.0665,
      "step": 14500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.8368939161300659,
      "learning_rate": 0.000925,
      "loss": 3.0562,
      "step": 15000
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.7633489370346069,
      "learning_rate": 0.0009225,
      "loss": 3.041,
      "step": 15500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9517515301704407,
      "learning_rate": 0.00092,
      "loss": 3.0201,
      "step": 16000
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.8367863297462463,
      "learning_rate": 0.0009175,
      "loss": 3.0235,
      "step": 16500
    },
    {
      "epoch": 0.085,
      "grad_norm": 1.1121214628219604,
      "learning_rate": 0.000915,
      "loss": 3.0006,
      "step": 17000
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.9447916150093079,
      "learning_rate": 0.0009125,
      "loss": 2.9829,
      "step": 17500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9294823408126831,
      "learning_rate": 0.00091,
      "loss": 2.9911,
      "step": 18000
    },
    {
      "epoch": 0.0925,
      "grad_norm": 1.0713508129119873,
      "learning_rate": 0.0009075,
      "loss": 2.9579,
      "step": 18500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.9292083382606506,
      "learning_rate": 0.0009050000000000001,
      "loss": 2.9553,
      "step": 19000
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.851689338684082,
      "learning_rate": 0.0009025,
      "loss": 2.9474,
      "step": 19500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9567867517471313,
      "learning_rate": 0.0009000000000000001,
      "loss": 2.9465,
      "step": 20000
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.8697699308395386,
      "learning_rate": 0.0008975,
      "loss": 2.9552,
      "step": 20500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.8967899084091187,
      "learning_rate": 0.0008950000000000001,
      "loss": 2.9307,
      "step": 21000
    },
    {
      "epoch": 0.1075,
      "grad_norm": 1.3089841604232788,
      "learning_rate": 0.0008925,
      "loss": 2.9111,
      "step": 21500
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2371834516525269,
      "learning_rate": 0.0008900000000000001,
      "loss": 2.8932,
      "step": 22000
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.9674844741821289,
      "learning_rate": 0.0008874999999999999,
      "loss": 2.9052,
      "step": 22500
    },
    {
      "epoch": 0.115,
      "grad_norm": 1.0917068719863892,
      "learning_rate": 0.000885,
      "loss": 2.8877,
      "step": 23000
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.0696545839309692,
      "learning_rate": 0.0008824999999999999,
      "loss": 2.872,
      "step": 23500
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0600378513336182,
      "learning_rate": 0.00088,
      "loss": 2.8756,
      "step": 24000
    },
    {
      "epoch": 0.1225,
      "grad_norm": 1.0305356979370117,
      "learning_rate": 0.0008774999999999999,
      "loss": 2.8704,
      "step": 24500
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.2939332723617554,
      "learning_rate": 0.000875,
      "loss": 2.8484,
      "step": 25000
    },
    {
      "epoch": 0.1275,
      "grad_norm": 1.1360224485397339,
      "learning_rate": 0.0008725000000000001,
      "loss": 2.8642,
      "step": 25500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9483885169029236,
      "learning_rate": 0.00087,
      "loss": 2.8404,
      "step": 26000
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.9686812162399292,
      "learning_rate": 0.0008675000000000001,
      "loss": 2.8416,
      "step": 26500
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.1178901195526123,
      "learning_rate": 0.000865,
      "loss": 2.838,
      "step": 27000
    },
    {
      "epoch": 0.1375,
      "grad_norm": 1.0386428833007812,
      "learning_rate": 0.0008625000000000001,
      "loss": 2.8395,
      "step": 27500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8914787769317627,
      "learning_rate": 0.00086,
      "loss": 2.8306,
      "step": 28000
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.0630989074707031,
      "learning_rate": 0.0008575000000000001,
      "loss": 2.8255,
      "step": 28500
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.1409088373184204,
      "learning_rate": 0.000855,
      "loss": 2.7974,
      "step": 29000
    },
    {
      "epoch": 0.1475,
      "grad_norm": 1.0347046852111816,
      "learning_rate": 0.0008525000000000001,
      "loss": 2.8033,
      "step": 29500
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2211698293685913,
      "learning_rate": 0.00085,
      "loss": 2.8025,
      "step": 30000
    },
    {
      "epoch": 0.1525,
      "grad_norm": 1.0087406635284424,
      "learning_rate": 0.0008475000000000001,
      "loss": 2.7999,
      "step": 30500
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.121537446975708,
      "learning_rate": 0.0008449999999999999,
      "loss": 2.7894,
      "step": 31000
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.9162954092025757,
      "learning_rate": 0.0008425,
      "loss": 2.7766,
      "step": 31500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1603937149047852,
      "learning_rate": 0.00084,
      "loss": 2.788,
      "step": 32000
    },
    {
      "epoch": 0.1625,
      "grad_norm": 1.2088717222213745,
      "learning_rate": 0.0008375,
      "loss": 2.7807,
      "step": 32500
    },
    {
      "epoch": 0.165,
      "grad_norm": 1.125014305114746,
      "learning_rate": 0.000835,
      "loss": 2.7625,
      "step": 33000
    },
    {
      "epoch": 0.1675,
      "grad_norm": 1.1757583618164062,
      "learning_rate": 0.0008325,
      "loss": 2.7557,
      "step": 33500
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1115511655807495,
      "learning_rate": 0.00083,
      "loss": 2.7546,
      "step": 34000
    },
    {
      "epoch": 0.1725,
      "grad_norm": 1.0750247240066528,
      "learning_rate": 0.0008275,
      "loss": 2.7477,
      "step": 34500
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.1002427339553833,
      "learning_rate": 0.000825,
      "loss": 2.7447,
      "step": 35000
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.412224292755127,
      "learning_rate": 0.0008225,
      "loss": 2.7441,
      "step": 35500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.4275981187820435,
      "learning_rate": 0.00082,
      "loss": 2.7408,
      "step": 36000
    },
    {
      "epoch": 0.1825,
      "grad_norm": 1.176244854927063,
      "learning_rate": 0.0008175,
      "loss": 2.7346,
      "step": 36500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.9856649041175842,
      "learning_rate": 0.000815,
      "loss": 2.7387,
      "step": 37000
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.0919283628463745,
      "learning_rate": 0.0008125000000000001,
      "loss": 2.7224,
      "step": 37500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1833736896514893,
      "learning_rate": 0.0008100000000000001,
      "loss": 2.7307,
      "step": 38000
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.0535796880722046,
      "learning_rate": 0.0008075000000000001,
      "loss": 2.7365,
      "step": 38500
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.092108964920044,
      "learning_rate": 0.000805,
      "loss": 2.7223,
      "step": 39000
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.1923973560333252,
      "learning_rate": 0.0008025,
      "loss": 2.7051,
      "step": 39500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0274531841278076,
      "learning_rate": 0.0008,
      "loss": 2.7125,
      "step": 40000
    },
    {
      "epoch": 0.2025,
      "grad_norm": 1.0947233438491821,
      "learning_rate": 0.0007975,
      "loss": 2.6869,
      "step": 40500
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.1230779886245728,
      "learning_rate": 0.000795,
      "loss": 2.7021,
      "step": 41000
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.181361198425293,
      "learning_rate": 0.0007925,
      "loss": 2.698,
      "step": 41500
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0453643798828125,
      "learning_rate": 0.00079,
      "loss": 2.7018,
      "step": 42000
    },
    {
      "epoch": 0.2125,
      "grad_norm": 1.0722399950027466,
      "learning_rate": 0.0007875,
      "loss": 2.6913,
      "step": 42500
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.1774475574493408,
      "learning_rate": 0.000785,
      "loss": 2.6854,
      "step": 43000
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.176604986190796,
      "learning_rate": 0.0007825,
      "loss": 2.7051,
      "step": 43500
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2341505289077759,
      "learning_rate": 0.0007800000000000001,
      "loss": 2.6857,
      "step": 44000
    },
    {
      "epoch": 0.2225,
      "grad_norm": 1.2441327571868896,
      "learning_rate": 0.0007775,
      "loss": 2.6876,
      "step": 44500
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.1235544681549072,
      "learning_rate": 0.0007750000000000001,
      "loss": 2.6893,
      "step": 45000
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.0556284189224243,
      "learning_rate": 0.0007725,
      "loss": 2.672,
      "step": 45500
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0333244800567627,
      "learning_rate": 0.0007700000000000001,
      "loss": 2.6667,
      "step": 46000
    },
    {
      "epoch": 0.2325,
      "grad_norm": 1.2264842987060547,
      "learning_rate": 0.0007675,
      "loss": 2.6662,
      "step": 46500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.142416000366211,
      "learning_rate": 0.0007650000000000001,
      "loss": 2.6608,
      "step": 47000
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.2721446752548218,
      "learning_rate": 0.0007624999999999999,
      "loss": 2.6638,
      "step": 47500
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2089534997940063,
      "learning_rate": 0.00076,
      "loss": 2.6477,
      "step": 48000
    },
    {
      "epoch": 0.2425,
      "grad_norm": 1.1638340950012207,
      "learning_rate": 0.0007574999999999999,
      "loss": 2.6629,
      "step": 48500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.196699857711792,
      "learning_rate": 0.000755,
      "loss": 2.6498,
      "step": 49000
    },
    {
      "epoch": 0.2475,
      "grad_norm": 1.2342437505722046,
      "learning_rate": 0.0007524999999999999,
      "loss": 2.6536,
      "step": 49500
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.352423906326294,
      "learning_rate": 0.00075,
      "loss": 2.6458,
      "step": 50000
    },
    {
      "epoch": 0.2525,
      "grad_norm": 1.1785955429077148,
      "learning_rate": 0.0007475000000000001,
      "loss": 2.6268,
      "step": 50500
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.245163083076477,
      "learning_rate": 0.000745,
      "loss": 2.6324,
      "step": 51000
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.4635578393936157,
      "learning_rate": 0.0007425000000000001,
      "loss": 2.6308,
      "step": 51500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1202234029769897,
      "learning_rate": 0.00074,
      "loss": 2.6379,
      "step": 52000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 1.1809933185577393,
      "learning_rate": 0.0007375000000000001,
      "loss": 2.639,
      "step": 52500
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.1292095184326172,
      "learning_rate": 0.000735,
      "loss": 2.6205,
      "step": 53000
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.2224782705307007,
      "learning_rate": 0.0007325000000000001,
      "loss": 2.6129,
      "step": 53500
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2608535289764404,
      "learning_rate": 0.00073,
      "loss": 2.6339,
      "step": 54000
    },
    {
      "epoch": 0.2725,
      "grad_norm": 1.0644410848617554,
      "learning_rate": 0.0007275000000000001,
      "loss": 2.6158,
      "step": 54500
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.3610315322875977,
      "learning_rate": 0.000725,
      "loss": 2.6055,
      "step": 55000
    },
    {
      "epoch": 0.2775,
      "grad_norm": 1.3895888328552246,
      "learning_rate": 0.0007225,
      "loss": 2.6105,
      "step": 55500
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.24498450756073,
      "learning_rate": 0.0007199999999999999,
      "loss": 2.6021,
      "step": 56000
    },
    {
      "epoch": 0.2825,
      "grad_norm": 1.0635216236114502,
      "learning_rate": 0.0007175,
      "loss": 2.6124,
      "step": 56500
    },
    {
      "epoch": 0.285,
      "grad_norm": 1.213270664215088,
      "learning_rate": 0.000715,
      "loss": 2.6023,
      "step": 57000
    },
    {
      "epoch": 0.2875,
      "grad_norm": 1.1598535776138306,
      "learning_rate": 0.0007125,
      "loss": 2.6056,
      "step": 57500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2860392332077026,
      "learning_rate": 0.00071,
      "loss": 2.6025,
      "step": 58000
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.0315123796463013,
      "learning_rate": 0.0007075,
      "loss": 2.5961,
      "step": 58500
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.159761667251587,
      "learning_rate": 0.000705,
      "loss": 2.5822,
      "step": 59000
    },
    {
      "epoch": 0.2975,
      "grad_norm": 1.1458430290222168,
      "learning_rate": 0.0007025,
      "loss": 2.5803,
      "step": 59500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1101123094558716,
      "learning_rate": 0.0007,
      "loss": 2.6012,
      "step": 60000
    },
    {
      "epoch": 0.3025,
      "grad_norm": 1.1366331577301025,
      "learning_rate": 0.0006975,
      "loss": 2.5868,
      "step": 60500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.4242006540298462,
      "learning_rate": 0.000695,
      "loss": 2.5852,
      "step": 61000
    },
    {
      "epoch": 0.3075,
      "grad_norm": 1.2174129486083984,
      "learning_rate": 0.0006925,
      "loss": 2.5854,
      "step": 61500
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0907721519470215,
      "learning_rate": 0.00069,
      "loss": 2.5869,
      "step": 62000
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.4873567819595337,
      "learning_rate": 0.0006875,
      "loss": 2.5703,
      "step": 62500
    },
    {
      "epoch": 0.315,
      "grad_norm": 1.212533950805664,
      "learning_rate": 0.0006850000000000001,
      "loss": 2.5598,
      "step": 63000
    },
    {
      "epoch": 0.3175,
      "grad_norm": 1.2037177085876465,
      "learning_rate": 0.0006825000000000001,
      "loss": 2.5846,
      "step": 63500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4359643459320068,
      "learning_rate": 0.00068,
      "loss": 2.5752,
      "step": 64000
    },
    {
      "epoch": 0.3225,
      "grad_norm": 1.1616700887680054,
      "learning_rate": 0.0006775,
      "loss": 2.5606,
      "step": 64500
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.3300976753234863,
      "learning_rate": 0.000675,
      "loss": 2.5818,
      "step": 65000
    },
    {
      "epoch": 0.3275,
      "grad_norm": 1.4427012205123901,
      "learning_rate": 0.0006725,
      "loss": 2.5693,
      "step": 65500
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2896676063537598,
      "learning_rate": 0.00067,
      "loss": 2.5679,
      "step": 66000
    },
    {
      "epoch": 0.3325,
      "grad_norm": 1.2162636518478394,
      "learning_rate": 0.0006675,
      "loss": 2.5726,
      "step": 66500
    },
    {
      "epoch": 0.335,
      "grad_norm": 1.2442551851272583,
      "learning_rate": 0.000665,
      "loss": 2.5652,
      "step": 67000
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.185120701789856,
      "learning_rate": 0.0006625,
      "loss": 2.5548,
      "step": 67500
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.190158724784851,
      "learning_rate": 0.00066,
      "loss": 2.5626,
      "step": 68000
    },
    {
      "epoch": 0.3425,
      "grad_norm": 1.2793869972229004,
      "learning_rate": 0.0006575,
      "loss": 2.5471,
      "step": 68500
    },
    {
      "epoch": 0.345,
      "grad_norm": 1.6477580070495605,
      "learning_rate": 0.0006550000000000001,
      "loss": 2.559,
      "step": 69000
    },
    {
      "epoch": 0.3475,
      "grad_norm": 1.2688899040222168,
      "learning_rate": 0.0006525,
      "loss": 2.5488,
      "step": 69500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.10979163646698,
      "learning_rate": 0.0006500000000000001,
      "loss": 2.5593,
      "step": 70000
    },
    {
      "epoch": 0.3525,
      "grad_norm": 1.5122793912887573,
      "learning_rate": 0.0006475,
      "loss": 2.5398,
      "step": 70500
    },
    {
      "epoch": 0.355,
      "grad_norm": 1.175272822380066,
      "learning_rate": 0.0006450000000000001,
      "loss": 2.5576,
      "step": 71000
    },
    {
      "epoch": 0.3575,
      "grad_norm": 1.5294508934020996,
      "learning_rate": 0.0006425,
      "loss": 2.5369,
      "step": 71500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3700798749923706,
      "learning_rate": 0.00064,
      "loss": 2.5527,
      "step": 72000
    },
    {
      "epoch": 0.3625,
      "grad_norm": 1.304424524307251,
      "learning_rate": 0.0006374999999999999,
      "loss": 2.5334,
      "step": 72500
    },
    {
      "epoch": 0.365,
      "grad_norm": 1.2237969636917114,
      "learning_rate": 0.000635,
      "loss": 2.5321,
      "step": 73000
    },
    {
      "epoch": 0.3675,
      "grad_norm": 1.327894926071167,
      "learning_rate": 0.0006324999999999999,
      "loss": 2.5253,
      "step": 73500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1829038858413696,
      "learning_rate": 0.00063,
      "loss": 2.5194,
      "step": 74000
    },
    {
      "epoch": 0.3725,
      "grad_norm": 1.3238803148269653,
      "learning_rate": 0.0006274999999999999,
      "loss": 2.509,
      "step": 74500
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.1618770360946655,
      "learning_rate": 0.000625,
      "loss": 2.5277,
      "step": 75000
    },
    {
      "epoch": 0.3775,
      "grad_norm": 1.0994969606399536,
      "learning_rate": 0.0006225000000000001,
      "loss": 2.5038,
      "step": 75500
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.41861891746521,
      "learning_rate": 0.00062,
      "loss": 2.5235,
      "step": 76000
    },
    {
      "epoch": 0.3825,
      "grad_norm": 1.3342241048812866,
      "learning_rate": 0.0006175000000000001,
      "loss": 2.517,
      "step": 76500
    },
    {
      "epoch": 0.385,
      "grad_norm": 1.251430630683899,
      "learning_rate": 0.000615,
      "loss": 2.5183,
      "step": 77000
    },
    {
      "epoch": 0.3875,
      "grad_norm": 1.2695258855819702,
      "learning_rate": 0.0006125000000000001,
      "loss": 2.5467,
      "step": 77500
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.6443955898284912,
      "learning_rate": 0.00061,
      "loss": 2.5265,
      "step": 78000
    },
    {
      "epoch": 0.3925,
      "grad_norm": 1.245822548866272,
      "learning_rate": 0.0006075000000000001,
      "loss": 2.504,
      "step": 78500
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.3625186681747437,
      "learning_rate": 0.000605,
      "loss": 2.5285,
      "step": 79000
    },
    {
      "epoch": 0.3975,
      "grad_norm": 1.5215380191802979,
      "learning_rate": 0.0006025000000000001,
      "loss": 2.5044,
      "step": 79500
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1735068559646606,
      "learning_rate": 0.0006,
      "loss": 2.5077,
      "step": 80000
    },
    {
      "epoch": 0.4025,
      "grad_norm": 1.173115849494934,
      "learning_rate": 0.0005975,
      "loss": 2.5074,
      "step": 80500
    },
    {
      "epoch": 0.405,
      "grad_norm": 1.2329570055007935,
      "learning_rate": 0.0005949999999999999,
      "loss": 2.5146,
      "step": 81000
    },
    {
      "epoch": 0.4075,
      "grad_norm": 1.2373815774917603,
      "learning_rate": 0.0005925,
      "loss": 2.5176,
      "step": 81500
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2749818563461304,
      "learning_rate": 0.00059,
      "loss": 2.4975,
      "step": 82000
    },
    {
      "epoch": 0.4125,
      "grad_norm": 1.307542324066162,
      "learning_rate": 0.0005875,
      "loss": 2.5211,
      "step": 82500
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.217214822769165,
      "learning_rate": 0.000585,
      "loss": 2.5067,
      "step": 83000
    },
    {
      "epoch": 0.4175,
      "grad_norm": 1.3427107334136963,
      "learning_rate": 0.0005825,
      "loss": 2.4879,
      "step": 83500
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4521050453186035,
      "learning_rate": 0.00058,
      "loss": 2.5047,
      "step": 84000
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.285526156425476,
      "learning_rate": 0.0005775,
      "loss": 2.4909,
      "step": 84500
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.1690034866333008,
      "learning_rate": 0.000575,
      "loss": 2.4892,
      "step": 85000
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.278473138809204,
      "learning_rate": 0.0005725,
      "loss": 2.4913,
      "step": 85500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.189714789390564,
      "learning_rate": 0.00057,
      "loss": 2.5012,
      "step": 86000
    },
    {
      "epoch": 0.4325,
      "grad_norm": 1.3932671546936035,
      "learning_rate": 0.0005675,
      "loss": 2.4844,
      "step": 86500
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.3416179418563843,
      "learning_rate": 0.000565,
      "loss": 2.4871,
      "step": 87000
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.1349458694458008,
      "learning_rate": 0.0005625000000000001,
      "loss": 2.489,
      "step": 87500
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1392786502838135,
      "learning_rate": 0.0005600000000000001,
      "loss": 2.4845,
      "step": 88000
    },
    {
      "epoch": 0.4425,
      "grad_norm": 1.1887497901916504,
      "learning_rate": 0.0005575,
      "loss": 2.4849,
      "step": 88500
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.2394605875015259,
      "learning_rate": 0.000555,
      "loss": 2.4777,
      "step": 89000
    },
    {
      "epoch": 0.4475,
      "grad_norm": 1.4079577922821045,
      "learning_rate": 0.0005525,
      "loss": 2.4803,
      "step": 89500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5916264057159424,
      "learning_rate": 0.00055,
      "loss": 2.4792,
      "step": 90000
    },
    {
      "epoch": 0.4525,
      "grad_norm": 1.1867661476135254,
      "learning_rate": 0.0005475,
      "loss": 2.473,
      "step": 90500
    },
    {
      "epoch": 0.455,
      "grad_norm": 1.2700849771499634,
      "learning_rate": 0.000545,
      "loss": 2.4826,
      "step": 91000
    },
    {
      "epoch": 0.4575,
      "grad_norm": 1.4177531003952026,
      "learning_rate": 0.0005425,
      "loss": 2.4702,
      "step": 91500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2190029621124268,
      "learning_rate": 0.00054,
      "loss": 2.4758,
      "step": 92000
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.2855703830718994,
      "learning_rate": 0.0005375,
      "loss": 2.4738,
      "step": 92500
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.2829073667526245,
      "learning_rate": 0.000535,
      "loss": 2.4588,
      "step": 93000
    },
    {
      "epoch": 0.4675,
      "grad_norm": 1.5247169733047485,
      "learning_rate": 0.0005325,
      "loss": 2.4731,
      "step": 93500
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2491317987442017,
      "learning_rate": 0.0005300000000000001,
      "loss": 2.465,
      "step": 94000
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.4473001956939697,
      "learning_rate": 0.0005275,
      "loss": 2.4442,
      "step": 94500
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.3093960285186768,
      "learning_rate": 0.0005250000000000001,
      "loss": 2.4695,
      "step": 95000
    },
    {
      "epoch": 0.4775,
      "grad_norm": 1.3767592906951904,
      "learning_rate": 0.0005225,
      "loss": 2.4501,
      "step": 95500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2657880783081055,
      "learning_rate": 0.0005200000000000001,
      "loss": 2.4828,
      "step": 96000
    },
    {
      "epoch": 0.4825,
      "grad_norm": 1.5744870901107788,
      "learning_rate": 0.0005175,
      "loss": 2.455,
      "step": 96500
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.2451268434524536,
      "learning_rate": 0.000515,
      "loss": 2.4599,
      "step": 97000
    },
    {
      "epoch": 0.4875,
      "grad_norm": 1.2650648355484009,
      "learning_rate": 0.0005124999999999999,
      "loss": 2.4627,
      "step": 97500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.581823468208313,
      "learning_rate": 0.00051,
      "loss": 2.4513,
      "step": 98000
    },
    {
      "epoch": 0.4925,
      "grad_norm": 1.1189497709274292,
      "learning_rate": 0.0005074999999999999,
      "loss": 2.4395,
      "step": 98500
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.4968663454055786,
      "learning_rate": 0.000505,
      "loss": 2.4524,
      "step": 99000
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.2964695692062378,
      "learning_rate": 0.0005024999999999999,
      "loss": 2.4485,
      "step": 99500
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3327680826187134,
      "learning_rate": 0.0005,
      "loss": 2.4441,
      "step": 100000
    },
    {
      "epoch": 0.5025,
      "grad_norm": 1.3612688779830933,
      "learning_rate": 0.0004975,
      "loss": 2.4494,
      "step": 100500
    },
    {
      "epoch": 0.505,
      "grad_norm": 1.3942254781723022,
      "learning_rate": 0.000495,
      "loss": 2.4465,
      "step": 101000
    },
    {
      "epoch": 0.5075,
      "grad_norm": 1.4652396440505981,
      "learning_rate": 0.0004925,
      "loss": 2.4427,
      "step": 101500
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2429900169372559,
      "learning_rate": 0.00049,
      "loss": 2.4565,
      "step": 102000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 1.3130676746368408,
      "learning_rate": 0.0004875,
      "loss": 2.4448,
      "step": 102500
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.3213344812393188,
      "learning_rate": 0.00048499999999999997,
      "loss": 2.446,
      "step": 103000
    },
    {
      "epoch": 0.5175,
      "grad_norm": 1.4190666675567627,
      "learning_rate": 0.0004825,
      "loss": 2.4304,
      "step": 103500
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2630705833435059,
      "learning_rate": 0.00048,
      "loss": 2.4451,
      "step": 104000
    },
    {
      "epoch": 0.5225,
      "grad_norm": 1.918549656867981,
      "learning_rate": 0.0004775,
      "loss": 2.4482,
      "step": 104500
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.3466218709945679,
      "learning_rate": 0.000475,
      "loss": 2.428,
      "step": 105000
    },
    {
      "epoch": 0.5275,
      "grad_norm": 1.4195036888122559,
      "learning_rate": 0.0004725,
      "loss": 2.4224,
      "step": 105500
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2400728464126587,
      "learning_rate": 0.00047,
      "loss": 2.4326,
      "step": 106000
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.2677850723266602,
      "learning_rate": 0.00046750000000000003,
      "loss": 2.4272,
      "step": 106500
    },
    {
      "epoch": 0.535,
      "grad_norm": 1.3076339960098267,
      "learning_rate": 0.000465,
      "loss": 2.4295,
      "step": 107000
    },
    {
      "epoch": 0.5375,
      "grad_norm": 1.2251678705215454,
      "learning_rate": 0.0004625,
      "loss": 2.4204,
      "step": 107500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2615551948547363,
      "learning_rate": 0.00046,
      "loss": 2.4317,
      "step": 108000
    },
    {
      "epoch": 0.5425,
      "grad_norm": 1.229413390159607,
      "learning_rate": 0.0004575,
      "loss": 2.4191,
      "step": 108500
    },
    {
      "epoch": 0.545,
      "grad_norm": 1.1645207405090332,
      "learning_rate": 0.000455,
      "loss": 2.4211,
      "step": 109000
    },
    {
      "epoch": 0.5475,
      "grad_norm": 1.280490517616272,
      "learning_rate": 0.00045250000000000005,
      "loss": 2.4355,
      "step": 109500
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4928994178771973,
      "learning_rate": 0.00045000000000000004,
      "loss": 2.429,
      "step": 110000
    },
    {
      "epoch": 0.5525,
      "grad_norm": 1.2537360191345215,
      "learning_rate": 0.00044750000000000004,
      "loss": 2.4086,
      "step": 110500
    },
    {
      "epoch": 0.555,
      "grad_norm": 1.306692361831665,
      "learning_rate": 0.00044500000000000003,
      "loss": 2.4199,
      "step": 111000
    },
    {
      "epoch": 0.5575,
      "grad_norm": 1.2602663040161133,
      "learning_rate": 0.0004425,
      "loss": 2.4175,
      "step": 111500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.2455992698669434,
      "learning_rate": 0.00044,
      "loss": 2.4099,
      "step": 112000
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.3404403924942017,
      "learning_rate": 0.0004375,
      "loss": 2.4215,
      "step": 112500
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.3865820169448853,
      "learning_rate": 0.000435,
      "loss": 2.4202,
      "step": 113000
    },
    {
      "epoch": 0.5675,
      "grad_norm": 1.326233983039856,
      "learning_rate": 0.0004325,
      "loss": 2.4168,
      "step": 113500
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3309409618377686,
      "learning_rate": 0.00043,
      "loss": 2.4207,
      "step": 114000
    },
    {
      "epoch": 0.5725,
      "grad_norm": 1.402309775352478,
      "learning_rate": 0.0004275,
      "loss": 2.4084,
      "step": 114500
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.4408575296401978,
      "learning_rate": 0.000425,
      "loss": 2.4017,
      "step": 115000
    },
    {
      "epoch": 0.5775,
      "grad_norm": 1.4004656076431274,
      "learning_rate": 0.00042249999999999997,
      "loss": 2.4289,
      "step": 115500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3168294429779053,
      "learning_rate": 0.00042,
      "loss": 2.4086,
      "step": 116000
    },
    {
      "epoch": 0.5825,
      "grad_norm": 1.4937090873718262,
      "learning_rate": 0.0004175,
      "loss": 2.4069,
      "step": 116500
    },
    {
      "epoch": 0.585,
      "grad_norm": 1.2778342962265015,
      "learning_rate": 0.000415,
      "loss": 2.4346,
      "step": 117000
    },
    {
      "epoch": 0.5875,
      "grad_norm": 1.3556197881698608,
      "learning_rate": 0.0004125,
      "loss": 2.3907,
      "step": 117500
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.302394986152649,
      "learning_rate": 0.00041,
      "loss": 2.4104,
      "step": 118000
    },
    {
      "epoch": 0.5925,
      "grad_norm": 1.370320200920105,
      "learning_rate": 0.0004075,
      "loss": 2.3983,
      "step": 118500
    },
    {
      "epoch": 0.595,
      "grad_norm": 1.4057753086090088,
      "learning_rate": 0.00040500000000000003,
      "loss": 2.4102,
      "step": 119000
    },
    {
      "epoch": 0.5975,
      "grad_norm": 1.3597441911697388,
      "learning_rate": 0.0004025,
      "loss": 2.4023,
      "step": 119500
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.4020063877105713,
      "learning_rate": 0.0004,
      "loss": 2.4005,
      "step": 120000
    },
    {
      "epoch": 0.6025,
      "grad_norm": 1.5373164415359497,
      "learning_rate": 0.0003975,
      "loss": 2.4011,
      "step": 120500
    },
    {
      "epoch": 0.605,
      "grad_norm": 1.4885282516479492,
      "learning_rate": 0.000395,
      "loss": 2.4071,
      "step": 121000
    },
    {
      "epoch": 0.6075,
      "grad_norm": 1.3970940113067627,
      "learning_rate": 0.0003925,
      "loss": 2.4014,
      "step": 121500
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3413589000701904,
      "learning_rate": 0.00039000000000000005,
      "loss": 2.3967,
      "step": 122000
    },
    {
      "epoch": 0.6125,
      "grad_norm": 1.3173627853393555,
      "learning_rate": 0.00038750000000000004,
      "loss": 2.388,
      "step": 122500
    },
    {
      "epoch": 0.615,
      "grad_norm": 1.5154595375061035,
      "learning_rate": 0.00038500000000000003,
      "loss": 2.398,
      "step": 123000
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.2370400428771973,
      "learning_rate": 0.00038250000000000003,
      "loss": 2.403,
      "step": 123500
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.398728370666504,
      "learning_rate": 0.00038,
      "loss": 2.3872,
      "step": 124000
    },
    {
      "epoch": 0.6225,
      "grad_norm": 1.462702751159668,
      "learning_rate": 0.0003775,
      "loss": 2.3924,
      "step": 124500
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.2476881742477417,
      "learning_rate": 0.000375,
      "loss": 2.4033,
      "step": 125000
    },
    {
      "epoch": 0.6275,
      "grad_norm": 1.3778973817825317,
      "learning_rate": 0.0003725,
      "loss": 2.37,
      "step": 125500
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4979310035705566,
      "learning_rate": 0.00037,
      "loss": 2.4024,
      "step": 126000
    },
    {
      "epoch": 0.6325,
      "grad_norm": 1.2832008600234985,
      "learning_rate": 0.0003675,
      "loss": 2.379,
      "step": 126500
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.2076787948608398,
      "learning_rate": 0.000365,
      "loss": 2.3846,
      "step": 127000
    },
    {
      "epoch": 0.6375,
      "grad_norm": 1.3985862731933594,
      "learning_rate": 0.0003625,
      "loss": 2.382,
      "step": 127500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4206645488739014,
      "learning_rate": 0.00035999999999999997,
      "loss": 2.3789,
      "step": 128000
    },
    {
      "epoch": 0.6425,
      "grad_norm": 1.4542500972747803,
      "learning_rate": 0.0003575,
      "loss": 2.3857,
      "step": 128500
    },
    {
      "epoch": 0.645,
      "grad_norm": 1.373868703842163,
      "learning_rate": 0.000355,
      "loss": 2.4051,
      "step": 129000
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.4070580005645752,
      "learning_rate": 0.0003525,
      "loss": 2.3724,
      "step": 129500
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3861318826675415,
      "learning_rate": 0.00035,
      "loss": 2.3817,
      "step": 130000
    },
    {
      "epoch": 0.6525,
      "grad_norm": 1.3111066818237305,
      "learning_rate": 0.0003475,
      "loss": 2.3718,
      "step": 130500
    },
    {
      "epoch": 0.655,
      "grad_norm": 1.4038245677947998,
      "learning_rate": 0.000345,
      "loss": 2.3711,
      "step": 131000
    },
    {
      "epoch": 0.6575,
      "grad_norm": 1.4160228967666626,
      "learning_rate": 0.00034250000000000003,
      "loss": 2.3745,
      "step": 131500
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.085659980773926,
      "learning_rate": 0.00034,
      "loss": 2.381,
      "step": 132000
    },
    {
      "epoch": 0.6625,
      "grad_norm": 1.4433846473693848,
      "learning_rate": 0.0003375,
      "loss": 2.3728,
      "step": 132500
    },
    {
      "epoch": 0.665,
      "grad_norm": 1.3829412460327148,
      "learning_rate": 0.000335,
      "loss": 2.375,
      "step": 133000
    },
    {
      "epoch": 0.6675,
      "grad_norm": 1.299735426902771,
      "learning_rate": 0.0003325,
      "loss": 2.3748,
      "step": 133500
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4110130071640015,
      "learning_rate": 0.00033,
      "loss": 2.3773,
      "step": 134000
    },
    {
      "epoch": 0.6725,
      "grad_norm": 1.356381893157959,
      "learning_rate": 0.00032750000000000005,
      "loss": 2.3579,
      "step": 134500
    },
    {
      "epoch": 0.675,
      "grad_norm": 1.238548755645752,
      "learning_rate": 0.00032500000000000004,
      "loss": 2.3587,
      "step": 135000
    },
    {
      "epoch": 0.6775,
      "grad_norm": 1.3275161981582642,
      "learning_rate": 0.00032250000000000003,
      "loss": 2.3678,
      "step": 135500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4048720598220825,
      "learning_rate": 0.00032,
      "loss": 2.3669,
      "step": 136000
    },
    {
      "epoch": 0.6825,
      "grad_norm": 1.4140863418579102,
      "learning_rate": 0.0003175,
      "loss": 2.3505,
      "step": 136500
    },
    {
      "epoch": 0.685,
      "grad_norm": 1.3528884649276733,
      "learning_rate": 0.000315,
      "loss": 2.3548,
      "step": 137000
    },
    {
      "epoch": 0.6875,
      "grad_norm": 1.373583436012268,
      "learning_rate": 0.0003125,
      "loss": 2.3676,
      "step": 137500
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3965498208999634,
      "learning_rate": 0.00031,
      "loss": 2.3527,
      "step": 138000
    },
    {
      "epoch": 0.6925,
      "grad_norm": 1.377035140991211,
      "learning_rate": 0.0003075,
      "loss": 2.3775,
      "step": 138500
    },
    {
      "epoch": 0.695,
      "grad_norm": 1.6240394115447998,
      "learning_rate": 0.000305,
      "loss": 2.3505,
      "step": 139000
    },
    {
      "epoch": 0.6975,
      "grad_norm": 1.3847341537475586,
      "learning_rate": 0.0003025,
      "loss": 2.3692,
      "step": 139500
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3725773096084595,
      "learning_rate": 0.0003,
      "loss": 2.358,
      "step": 140000
    },
    {
      "epoch": 0.7025,
      "grad_norm": 1.4918239116668701,
      "learning_rate": 0.00029749999999999997,
      "loss": 2.3593,
      "step": 140500
    },
    {
      "epoch": 0.705,
      "grad_norm": 1.3065567016601562,
      "learning_rate": 0.000295,
      "loss": 2.3644,
      "step": 141000
    },
    {
      "epoch": 0.7075,
      "grad_norm": 1.6065523624420166,
      "learning_rate": 0.0002925,
      "loss": 2.3598,
      "step": 141500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3867226839065552,
      "learning_rate": 0.00029,
      "loss": 2.3519,
      "step": 142000
    },
    {
      "epoch": 0.7125,
      "grad_norm": 1.4478182792663574,
      "learning_rate": 0.0002875,
      "loss": 2.3379,
      "step": 142500
    },
    {
      "epoch": 0.715,
      "grad_norm": 1.4357469081878662,
      "learning_rate": 0.000285,
      "loss": 2.3534,
      "step": 143000
    },
    {
      "epoch": 0.7175,
      "grad_norm": 1.5861223936080933,
      "learning_rate": 0.0002825,
      "loss": 2.3614,
      "step": 143500
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2678141593933105,
      "learning_rate": 0.00028000000000000003,
      "loss": 2.3542,
      "step": 144000
    },
    {
      "epoch": 0.7225,
      "grad_norm": 1.304714322090149,
      "learning_rate": 0.0002775,
      "loss": 2.3656,
      "step": 144500
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.3126198053359985,
      "learning_rate": 0.000275,
      "loss": 2.3503,
      "step": 145000
    },
    {
      "epoch": 0.7275,
      "grad_norm": 1.3671090602874756,
      "learning_rate": 0.0002725,
      "loss": 2.3528,
      "step": 145500
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.392712950706482,
      "learning_rate": 0.00027,
      "loss": 2.3417,
      "step": 146000
    },
    {
      "epoch": 0.7325,
      "grad_norm": 1.4570454359054565,
      "learning_rate": 0.0002675,
      "loss": 2.3443,
      "step": 146500
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.5052739381790161,
      "learning_rate": 0.00026500000000000004,
      "loss": 2.3547,
      "step": 147000
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.1884028911590576,
      "learning_rate": 0.00026250000000000004,
      "loss": 2.3359,
      "step": 147500
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.354118824005127,
      "learning_rate": 0.00026000000000000003,
      "loss": 2.3401,
      "step": 148000
    },
    {
      "epoch": 0.7425,
      "grad_norm": 1.2265206575393677,
      "learning_rate": 0.0002575,
      "loss": 2.3438,
      "step": 148500
    },
    {
      "epoch": 0.745,
      "grad_norm": 1.553040623664856,
      "learning_rate": 0.000255,
      "loss": 2.3578,
      "step": 149000
    },
    {
      "epoch": 0.7475,
      "grad_norm": 1.1760319471359253,
      "learning_rate": 0.0002525,
      "loss": 2.3345,
      "step": 149500
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3008936643600464,
      "learning_rate": 0.00025,
      "loss": 2.3511,
      "step": 150000
    },
    {
      "epoch": 0.7525,
      "grad_norm": 1.3419030904769897,
      "learning_rate": 0.0002475,
      "loss": 2.3244,
      "step": 150500
    },
    {
      "epoch": 0.755,
      "grad_norm": 1.4883390665054321,
      "learning_rate": 0.000245,
      "loss": 2.3326,
      "step": 151000
    },
    {
      "epoch": 0.7575,
      "grad_norm": 1.3414201736450195,
      "learning_rate": 0.00024249999999999999,
      "loss": 2.3528,
      "step": 151500
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3782609701156616,
      "learning_rate": 0.00024,
      "loss": 2.3388,
      "step": 152000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 1.2849268913269043,
      "learning_rate": 0.0002375,
      "loss": 2.3433,
      "step": 152500
    },
    {
      "epoch": 0.765,
      "grad_norm": 1.4225051403045654,
      "learning_rate": 0.000235,
      "loss": 2.3413,
      "step": 153000
    },
    {
      "epoch": 0.7675,
      "grad_norm": 1.3174197673797607,
      "learning_rate": 0.0002325,
      "loss": 2.3427,
      "step": 153500
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3929660320281982,
      "learning_rate": 0.00023,
      "loss": 2.3369,
      "step": 154000
    },
    {
      "epoch": 0.7725,
      "grad_norm": 1.5525544881820679,
      "learning_rate": 0.0002275,
      "loss": 2.3544,
      "step": 154500
    },
    {
      "epoch": 0.775,
      "grad_norm": 1.3268924951553345,
      "learning_rate": 0.00022500000000000002,
      "loss": 2.3265,
      "step": 155000
    },
    {
      "epoch": 0.7775,
      "grad_norm": 1.5433140993118286,
      "learning_rate": 0.00022250000000000001,
      "loss": 2.3266,
      "step": 155500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4345078468322754,
      "learning_rate": 0.00022,
      "loss": 2.3489,
      "step": 156000
    },
    {
      "epoch": 0.7825,
      "grad_norm": 1.3796595335006714,
      "learning_rate": 0.0002175,
      "loss": 2.3313,
      "step": 156500
    },
    {
      "epoch": 0.785,
      "grad_norm": 1.5518126487731934,
      "learning_rate": 0.000215,
      "loss": 2.3337,
      "step": 157000
    },
    {
      "epoch": 0.7875,
      "grad_norm": 1.3755813837051392,
      "learning_rate": 0.0002125,
      "loss": 2.3426,
      "step": 157500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2877323627471924,
      "learning_rate": 0.00021,
      "loss": 2.3304,
      "step": 158000
    },
    {
      "epoch": 0.7925,
      "grad_norm": 1.3224687576293945,
      "learning_rate": 0.0002075,
      "loss": 2.3314,
      "step": 158500
    },
    {
      "epoch": 0.795,
      "grad_norm": 1.434643268585205,
      "learning_rate": 0.000205,
      "loss": 2.3109,
      "step": 159000
    },
    {
      "epoch": 0.7975,
      "grad_norm": 1.5359097719192505,
      "learning_rate": 0.00020250000000000002,
      "loss": 2.3122,
      "step": 159500
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4138132333755493,
      "learning_rate": 0.0002,
      "loss": 2.3165,
      "step": 160000
    },
    {
      "epoch": 0.8025,
      "grad_norm": 1.4652358293533325,
      "learning_rate": 0.0001975,
      "loss": 2.319,
      "step": 160500
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.4885163307189941,
      "learning_rate": 0.00019500000000000002,
      "loss": 2.3154,
      "step": 161000
    },
    {
      "epoch": 0.8075,
      "grad_norm": 1.4217456579208374,
      "learning_rate": 0.00019250000000000002,
      "loss": 2.318,
      "step": 161500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3813084363937378,
      "learning_rate": 0.00019,
      "loss": 2.3226,
      "step": 162000
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.4594076871871948,
      "learning_rate": 0.0001875,
      "loss": 2.3249,
      "step": 162500
    },
    {
      "epoch": 0.815,
      "grad_norm": 1.376666784286499,
      "learning_rate": 0.000185,
      "loss": 2.3197,
      "step": 163000
    },
    {
      "epoch": 0.8175,
      "grad_norm": 1.4564435482025146,
      "learning_rate": 0.0001825,
      "loss": 2.3186,
      "step": 163500
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3470022678375244,
      "learning_rate": 0.00017999999999999998,
      "loss": 2.3108,
      "step": 164000
    },
    {
      "epoch": 0.8225,
      "grad_norm": 1.5028371810913086,
      "learning_rate": 0.0001775,
      "loss": 2.3211,
      "step": 164500
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.6277750730514526,
      "learning_rate": 0.000175,
      "loss": 2.3279,
      "step": 165000
    },
    {
      "epoch": 0.8275,
      "grad_norm": 1.4246165752410889,
      "learning_rate": 0.0001725,
      "loss": 2.3135,
      "step": 165500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2258714437484741,
      "learning_rate": 0.00017,
      "loss": 2.3264,
      "step": 166000
    },
    {
      "epoch": 0.8325,
      "grad_norm": 1.441460371017456,
      "learning_rate": 0.0001675,
      "loss": 2.3038,
      "step": 166500
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.3677560091018677,
      "learning_rate": 0.000165,
      "loss": 2.3281,
      "step": 167000
    },
    {
      "epoch": 0.8375,
      "grad_norm": 1.5067979097366333,
      "learning_rate": 0.00016250000000000002,
      "loss": 2.3173,
      "step": 167500
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4334262609481812,
      "learning_rate": 0.00016,
      "loss": 2.3155,
      "step": 168000
    },
    {
      "epoch": 0.8425,
      "grad_norm": 1.4888699054718018,
      "learning_rate": 0.0001575,
      "loss": 2.3017,
      "step": 168500
    },
    {
      "epoch": 0.845,
      "grad_norm": 1.3210880756378174,
      "learning_rate": 0.000155,
      "loss": 2.3106,
      "step": 169000
    },
    {
      "epoch": 0.8475,
      "grad_norm": 1.5260016918182373,
      "learning_rate": 0.0001525,
      "loss": 2.3149,
      "step": 169500
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3062254190444946,
      "learning_rate": 0.00015,
      "loss": 2.3042,
      "step": 170000
    },
    {
      "epoch": 0.8525,
      "grad_norm": 1.3573987483978271,
      "learning_rate": 0.0001475,
      "loss": 2.3036,
      "step": 170500
    },
    {
      "epoch": 0.855,
      "grad_norm": 1.4425063133239746,
      "learning_rate": 0.000145,
      "loss": 2.2985,
      "step": 171000
    },
    {
      "epoch": 0.8575,
      "grad_norm": 1.422297477722168,
      "learning_rate": 0.0001425,
      "loss": 2.3229,
      "step": 171500
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3409225940704346,
      "learning_rate": 0.00014000000000000001,
      "loss": 2.304,
      "step": 172000
    },
    {
      "epoch": 0.8625,
      "grad_norm": 1.417165994644165,
      "learning_rate": 0.0001375,
      "loss": 2.3093,
      "step": 172500
    },
    {
      "epoch": 0.865,
      "grad_norm": 1.2610007524490356,
      "learning_rate": 0.000135,
      "loss": 2.3047,
      "step": 173000
    },
    {
      "epoch": 0.8675,
      "grad_norm": 1.6256171464920044,
      "learning_rate": 0.00013250000000000002,
      "loss": 2.3017,
      "step": 173500
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4861235618591309,
      "learning_rate": 0.00013000000000000002,
      "loss": 2.306,
      "step": 174000
    },
    {
      "epoch": 0.8725,
      "grad_norm": 1.4698185920715332,
      "learning_rate": 0.0001275,
      "loss": 2.2937,
      "step": 174500
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.317317008972168,
      "learning_rate": 0.000125,
      "loss": 2.3134,
      "step": 175000
    },
    {
      "epoch": 0.8775,
      "grad_norm": 1.5145658254623413,
      "learning_rate": 0.0001225,
      "loss": 2.2988,
      "step": 175500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3901493549346924,
      "learning_rate": 0.00012,
      "loss": 2.3032,
      "step": 176000
    },
    {
      "epoch": 0.8825,
      "grad_norm": 1.3812024593353271,
      "learning_rate": 0.0001175,
      "loss": 2.29,
      "step": 176500
    },
    {
      "epoch": 0.885,
      "grad_norm": 1.330606460571289,
      "learning_rate": 0.000115,
      "loss": 2.3053,
      "step": 177000
    },
    {
      "epoch": 0.8875,
      "grad_norm": 1.6607328653335571,
      "learning_rate": 0.00011250000000000001,
      "loss": 2.2963,
      "step": 177500
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2931008338928223,
      "learning_rate": 0.00011,
      "loss": 2.2903,
      "step": 178000
    },
    {
      "epoch": 0.8925,
      "grad_norm": 1.3931611776351929,
      "learning_rate": 0.0001075,
      "loss": 2.2971,
      "step": 178500
    },
    {
      "epoch": 0.895,
      "grad_norm": 1.3606079816818237,
      "learning_rate": 0.000105,
      "loss": 2.2929,
      "step": 179000
    },
    {
      "epoch": 0.8975,
      "grad_norm": 1.577390193939209,
      "learning_rate": 0.0001025,
      "loss": 2.3068,
      "step": 179500
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7365632057189941,
      "learning_rate": 0.0001,
      "loss": 2.306,
      "step": 180000
    },
    {
      "epoch": 0.9025,
      "grad_norm": 1.466681957244873,
      "learning_rate": 9.750000000000001e-05,
      "loss": 2.286,
      "step": 180500
    },
    {
      "epoch": 0.905,
      "grad_norm": 1.4536901712417603,
      "learning_rate": 9.5e-05,
      "loss": 2.2833,
      "step": 181000
    },
    {
      "epoch": 0.9075,
      "grad_norm": 1.3885701894760132,
      "learning_rate": 9.25e-05,
      "loss": 2.2993,
      "step": 181500
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4460197687149048,
      "learning_rate": 8.999999999999999e-05,
      "loss": 2.2777,
      "step": 182000
    },
    {
      "epoch": 0.9125,
      "grad_norm": 1.3502237796783447,
      "learning_rate": 8.75e-05,
      "loss": 2.3068,
      "step": 182500
    },
    {
      "epoch": 0.915,
      "grad_norm": 1.3573994636535645,
      "learning_rate": 8.5e-05,
      "loss": 2.2911,
      "step": 183000
    },
    {
      "epoch": 0.9175,
      "grad_norm": 1.41732919216156,
      "learning_rate": 8.25e-05,
      "loss": 2.3035,
      "step": 183500
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.318837285041809,
      "learning_rate": 8e-05,
      "loss": 2.2946,
      "step": 184000
    },
    {
      "epoch": 0.9225,
      "grad_norm": 1.3134578466415405,
      "learning_rate": 7.75e-05,
      "loss": 2.2963,
      "step": 184500
    },
    {
      "epoch": 0.925,
      "grad_norm": 1.4997507333755493,
      "learning_rate": 7.5e-05,
      "loss": 2.2844,
      "step": 185000
    },
    {
      "epoch": 0.9275,
      "grad_norm": 1.4469670057296753,
      "learning_rate": 7.25e-05,
      "loss": 2.2899,
      "step": 185500
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2664798498153687,
      "learning_rate": 7.000000000000001e-05,
      "loss": 2.2951,
      "step": 186000
    },
    {
      "epoch": 0.9325,
      "grad_norm": 1.3254241943359375,
      "learning_rate": 6.75e-05,
      "loss": 2.2862,
      "step": 186500
    },
    {
      "epoch": 0.935,
      "grad_norm": 1.3391599655151367,
      "learning_rate": 6.500000000000001e-05,
      "loss": 2.2805,
      "step": 187000
    },
    {
      "epoch": 0.9375,
      "grad_norm": 1.4806880950927734,
      "learning_rate": 6.25e-05,
      "loss": 2.2816,
      "step": 187500
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3377078771591187,
      "learning_rate": 6e-05,
      "loss": 2.2842,
      "step": 188000
    },
    {
      "epoch": 0.9425,
      "grad_norm": 1.483493685722351,
      "learning_rate": 5.75e-05,
      "loss": 2.2854,
      "step": 188500
    },
    {
      "epoch": 0.945,
      "grad_norm": 1.25035560131073,
      "learning_rate": 5.5e-05,
      "loss": 2.2663,
      "step": 189000
    },
    {
      "epoch": 0.9475,
      "grad_norm": 1.5291439294815063,
      "learning_rate": 5.25e-05,
      "loss": 2.2944,
      "step": 189500
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3618189096450806,
      "learning_rate": 5e-05,
      "loss": 2.2809,
      "step": 190000
    },
    {
      "epoch": 0.9525,
      "grad_norm": 1.3547407388687134,
      "learning_rate": 4.75e-05,
      "loss": 2.2746,
      "step": 190500
    },
    {
      "epoch": 0.955,
      "grad_norm": 1.543359637260437,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 2.2793,
      "step": 191000
    },
    {
      "epoch": 0.9575,
      "grad_norm": 1.4348379373550415,
      "learning_rate": 4.25e-05,
      "loss": 2.2698,
      "step": 191500
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2683782577514648,
      "learning_rate": 4e-05,
      "loss": 2.2774,
      "step": 192000
    },
    {
      "epoch": 0.9625,
      "grad_norm": 1.3773573637008667,
      "learning_rate": 3.75e-05,
      "loss": 2.2847,
      "step": 192500
    },
    {
      "epoch": 0.965,
      "grad_norm": 1.4433553218841553,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 2.2788,
      "step": 193000
    },
    {
      "epoch": 0.9675,
      "grad_norm": 1.3562819957733154,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.2705,
      "step": 193500
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3612284660339355,
      "learning_rate": 3e-05,
      "loss": 2.2941,
      "step": 194000
    },
    {
      "epoch": 0.9725,
      "grad_norm": 1.3267213106155396,
      "learning_rate": 2.75e-05,
      "loss": 2.2881,
      "step": 194500
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.359210729598999,
      "learning_rate": 2.5e-05,
      "loss": 2.2888,
      "step": 195000
    },
    {
      "epoch": 0.9775,
      "grad_norm": 1.435955286026001,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 2.2756,
      "step": 195500
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3562061786651611,
      "learning_rate": 2e-05,
      "loss": 2.2831,
      "step": 196000
    },
    {
      "epoch": 0.9825,
      "grad_norm": 1.55404531955719,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 2.2766,
      "step": 196500
    },
    {
      "epoch": 0.985,
      "grad_norm": 1.4609864950180054,
      "learning_rate": 1.5e-05,
      "loss": 2.2769,
      "step": 197000
    },
    {
      "epoch": 0.9875,
      "grad_norm": 1.3841699361801147,
      "learning_rate": 1.25e-05,
      "loss": 2.2724,
      "step": 197500
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4925287961959839,
      "learning_rate": 1e-05,
      "loss": 2.2819,
      "step": 198000
    },
    {
      "epoch": 0.9925,
      "grad_norm": 1.563948631286621,
      "learning_rate": 7.5e-06,
      "loss": 2.2815,
      "step": 198500
    },
    {
      "epoch": 0.995,
      "grad_norm": 1.3663628101348877,
      "learning_rate": 5e-06,
      "loss": 2.2678,
      "step": 199000
    },
    {
      "epoch": 0.9975,
      "grad_norm": 1.2901108264923096,
      "learning_rate": 2.5e-06,
      "loss": 2.2607,
      "step": 199500
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3413445949554443,
      "learning_rate": 0.0,
      "loss": 2.2853,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.447037042688e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
